{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "australian-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (29,30,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "df = pd.read_csv(\"clusters.csv\", sep=';', encoding='utf-8').drop(columns = ['Unnamed: 0', 'index', 'Кластер'])\n",
    "df['Маржа'] = df['Маржа'].astype(str)\n",
    "df['Маржа'] = df['Маржа'].apply(lambda x: x.replace(',', '.'))\n",
    "df['Маржа'] = df['Маржа'].apply(lambda x: x.replace(' ', ''))\n",
    "df['Маржа'] = df['Маржа'].astype(float)\n",
    "df['СуммаСтроки'] = df['СуммаСтроки'].astype(str)\n",
    "df['СуммаСтроки'] = df['СуммаСтроки'].apply(lambda x: x.replace(',', '.'))\n",
    "df['СуммаСтроки'] = df['СуммаСтроки'].apply(lambda x: x.replace(' ', ''))\n",
    "df['СуммаСтроки'] = df['СуммаСтроки'].astype(float)\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].astype(str)\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].apply(lambda x: x.replace(',', '.'))\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].apply(lambda x: x.replace(' ', ''))\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].astype(float)\n",
    "df['СуммаЗаказаНаСайте'] = df['СуммаЗаказаНаСайте'].astype(str)\n",
    "df['СуммаЗаказаНаСайте'] = df['СуммаЗаказаНаСайте'].apply(lambda x: x.replace(',', '.'))\n",
    "df['СуммаЗаказаНаСайте'] = df['СуммаЗаказаНаСайте'].apply(lambda x: x.replace(' ', ''))\n",
    "df['СуммаЗаказаНаСайте'] = df['СуммаЗаказаНаСайте'].astype(float)\n",
    "df['Цена'] = df['Цена'].astype(str)\n",
    "df['Цена'] = df['Цена'].apply(lambda x: x.replace(',', '.'))\n",
    "df['Цена'] = df['Цена'].apply(lambda x: x.replace(' ', ''))\n",
    "df['Цена'] = df['Цена'].astype(float)\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].astype(str)\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].apply(lambda x: x.replace(',', '.'))\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].apply(lambda x: x.replace(' ', ''))\n",
    "df['ЦенаЗакупки'] = df['ЦенаЗакупки'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "australian-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Дата = pd.to_datetime(df.Дата)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "structured-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = df.loc[df.Дата.dt.month == 10]\n",
    "df_first = df.loc[df.Дата.dt.month != 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "sunset-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-268-c804322df6f2>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_first['МаржаПолная'] = df_first['Маржа'] * df_first['Количество']\n"
     ]
    }
   ],
   "source": [
    "display = pd.DataFrame()\n",
    "display['Id'] = df_first.drop_duplicates(subset='Телефон_new')['Телефон_new']\n",
    "display = display.reset_index(drop=True)\n",
    "df_first['МаржаПолная'] = df_first['Маржа'] * df_first['Количество']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "czech-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_non_dupe = df_first.drop_duplicates(subset='НомерЗаказаНаСайте').groupby('Телефон_new').mean()\n",
    "unique = df_first.groupby('Телефон_new').nunique()\n",
    "mean =  df_first.groupby('Телефон_new').mean()\n",
    "sum = df_first.groupby('Телефон_new').sum()\n",
    "non_dupe = df_first.drop_duplicates(subset='НомерЗаказаНаСайте')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "international-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>СуммаЗаказаНаСайте</th>\n",
       "      <th>Количество</th>\n",
       "      <th>Цена</th>\n",
       "      <th>СуммаСтроки</th>\n",
       "      <th>ЦенаЗакупки</th>\n",
       "      <th>МесяцДатыЗаказа</th>\n",
       "      <th>Маржа</th>\n",
       "      <th>НомерСтроки</th>\n",
       "      <th>КоличествоПроданоКлиенту</th>\n",
       "      <th>Доставка</th>\n",
       "      <th>МаржаПолная</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Телефон_new</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32565748-535549565054 5</th>\n",
       "      <td>1587.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>257.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>141.60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49574954-56524849545119</th>\n",
       "      <td>5215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>5870.86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-704.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-704.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55445748-51495749565771</th>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>753.15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55515349-57484951525673</th>\n",
       "      <td>1345.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>1531.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-186.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55515749-50495648505172</th>\n",
       "      <td>21305.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1284.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-285.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-285.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57535051-57555156485395</th>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>335.66</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57544955-51485756555597</th>\n",
       "      <td>39098.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38999.0</td>\n",
       "      <td>38999.0</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8999.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57545355-53485748575799</th>\n",
       "      <td>3212.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>1442.61</td>\n",
       "      <td>7.0</td>\n",
       "      <td>326.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>653.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57565350-49485256515193</th>\n",
       "      <td>899.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>552.00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57565355-57554952485597</th>\n",
       "      <td>769.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>705.78</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124551 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         СуммаЗаказаНаСайте  Количество     Цена  СуммаСтроки  \\\n",
       "Телефон_new                                                                     \n",
       "32565748-535549565054 5              1587.0         1.0    399.0        399.0   \n",
       "49574954-56524849545119              5215.0         1.0   5166.0       5166.0   \n",
       "55445748-51495749565771               799.0         1.0    799.0        799.0   \n",
       "55515349-57484951525673              1345.0         1.0   1345.0       1345.0   \n",
       "55515749-50495648505172             21305.0         1.0    999.0        999.0   \n",
       "...                                     ...         ...      ...          ...   \n",
       "57535051-57555156485395               498.0         1.0    399.0        399.0   \n",
       "57544955-51485756555597             39098.0         1.0  38999.0      38999.0   \n",
       "57545355-53485748575799              3212.0         2.0   1606.0       3212.0   \n",
       "57565350-49485256515193               899.0         1.0    599.0        599.0   \n",
       "57565355-57554952485597               769.0         1.0    720.0        720.0   \n",
       "\n",
       "                         ЦенаЗакупки  МесяцДатыЗаказа    Маржа  НомерСтроки  \\\n",
       "Телефон_new                                                                   \n",
       "32565748-535549565054 5       257.40             10.0   141.60          2.0   \n",
       "49574954-56524849545119      5870.86              8.0  -704.86          1.0   \n",
       "55445748-51495749565771       753.15             10.0    45.85          1.0   \n",
       "55515349-57484951525673      1531.00              8.0  -186.00          1.0   \n",
       "55515749-50495648505172      1284.00              8.0  -285.00          5.0   \n",
       "...                              ...              ...      ...          ...   \n",
       "57535051-57555156485395       335.66              8.0    63.34          1.0   \n",
       "57544955-51485756555597     30000.00             10.0  8999.00          1.0   \n",
       "57545355-53485748575799      1442.61              7.0   326.78          1.0   \n",
       "57565350-49485256515193       552.00              9.0    47.00          1.0   \n",
       "57565355-57554952485597       705.78              9.0    14.22          1.0   \n",
       "\n",
       "                         КоличествоПроданоКлиенту  Доставка  МаржаПолная  \n",
       "Телефон_new                                                               \n",
       "32565748-535549565054 5                       1.0       0.0       141.60  \n",
       "49574954-56524849545119                       1.0       1.0      -704.86  \n",
       "55445748-51495749565771                       1.0       0.0        45.85  \n",
       "55515349-57484951525673                       1.0       0.0      -186.00  \n",
       "55515749-50495648505172                       1.0       1.0      -285.00  \n",
       "...                                           ...       ...          ...  \n",
       "57535051-57555156485395                       1.0       1.0        63.34  \n",
       "57544955-51485756555597                       1.0       1.0      8999.00  \n",
       "57545355-53485748575799                       2.0       0.0       653.56  \n",
       "57565350-49485256515193                       1.0       1.0        47.00  \n",
       "57565355-57554952485597                       1.0       1.0        14.22  \n",
       "\n",
       "[124551 rows x 11 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_non_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "latest-administrator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-271-6e43287edbe8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bought['Итог'] = df_bought['Цена'] * df_bought['КоличествоПроданоКлиенту']\n",
      "<ipython-input-271-6e43287edbe8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bought['МаржаПолнаяВыкупленная'] = df_bought['Маржа'] * df_bought['КоличествоПроданоКлиенту']\n"
     ]
    }
   ],
   "source": [
    "df_bought = df_first[df_first.КоличествоПроданоКлиенту != 0]\n",
    "df_bought['Итог'] = df_bought['Цена'] * df_bought['КоличествоПроданоКлиенту']\n",
    "df_bought['МаржаПолнаяВыкупленная'] = df_bought['Маржа'] * df_bought['КоличествоПроданоКлиенту']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cellular-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_non_dupe_bought = df_bought.groupby(['Телефон_new', 'НомерЗаказаНаСайте']).sum()['Итог'].groupby('Телефон_new').mean()\n",
    "unique_bought = df_bought.groupby('Телефон_new').nunique()\n",
    "mean_bought =  df_bought.groupby('Телефон_new').mean()\n",
    "sum_bought = df_bought.groupby('Телефон_new').sum()\n",
    "group2 = df_bought.groupby(['Телефон_new', 'Группа2']).sum()\n",
    "group3 = df_bought.groupby(['Телефон_new', 'Группа3']).sum()\n",
    "type = df_bought.groupby(['Телефон_new', 'Тип']).sum()\n",
    "self_carry =  df_bought[(df_bought['МетодДоставки'] == 'Самовывоз') | (df_bought['МетодДоставки'] == 'Pick point')].groupby('Телефон_new').sum()['КоличествоПроданоКлиенту'] / df_bought.groupby('Телефон_new').sum()['КоличествоПроданоКлиенту']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "agreed-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(unique['НомерЗаказаНаСайте'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'НомерЗаказаНаСайте':'КоличествоЧеков'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "revised-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean_non_dupe['СуммаЗаказаНаСайте'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'СуммаЗаказаНаСайте':'СреднийЧек'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "sized-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean['Количество'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'Количество':'СреднееЧислоТоваровЧека'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "packed-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(sum['СуммаСтроки'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'СуммаСтроки':'Выручка'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "regulated-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(sum['Количество'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'Количество':'КоличествоТоваров'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "retained-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean['МаржаПолная'], left_on='Id', right_on='Телефон_new', how = 'inner')\n",
    "display = display.rename(columns={'МаржаПолная':'СредняяМаржа'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "weekly-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(unique_bought['НомерЗаказаНаСайте'], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'НомерЗаказаНаСайте':'КоличествоЧековВыкупленные'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "understood-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean_non_dupe_bought, left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'Итог':'СреднийЧекВыкупленные'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "normal-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean['КоличествоПроданоКлиенту'], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'КоличествоПроданоКлиенту':'СреднееЧислоТоваровЧекаВыкупленные'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "pacific-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(sum_bought['Итог'], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'Итог':'ВыручкаВыкупленная'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "relative-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(sum['КоличествоПроданоКлиенту'], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'КоличествоПроданоКлиенту':'КоличествоТоваровВыкупленные'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "apparent-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(mean_bought['МаржаПолнаяВыкупленная'], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.rename(columns={'МаржаПолнаяВыкупленная':'СредняяМаржаВыкупленная'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "molecular-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(self_carry.to_frame().fillna(0), left_on='Id', right_index=True, how = 'left')\n",
    "display = display.rename(columns={'КоличествоПроданоКлиенту':'ДоляСамовывоза'})\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "surface-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display[display.КоличествоТоваровВыкупленные != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "working-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "display['ДоляВыкупленных'] = display['КоличествоТоваровВыкупленные'] / display['КоличествоТоваров']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "prescription-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.Тип.unique():\n",
    "    display[i] = i\n",
    "    display = display.merge(type['КоличествоПроданоКлиенту'], left_on=['Id', i], right_on=['Телефон_new', 'Тип'], how='left')\n",
    "    display = display.drop(columns=[i])\n",
    "    display = display.rename(columns={'КоличествоПроданоКлиенту':i})\n",
    "    display = display.fillna(0)\n",
    "    display[i] = display[i] / display['КоличествоТоваровВыкупленные']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ranging-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.Группа2.unique():\n",
    "    display[i] = i\n",
    "    display = display.merge(group2['КоличествоПроданоКлиенту'], left_on=['Id', i], right_on=['Телефон_new', 'Группа2'], how='left')\n",
    "    display = display.drop(columns=[i])\n",
    "    display = display.rename(columns={'КоличествоПроданоКлиенту':i})\n",
    "    display = display.fillna(0)\n",
    "    display[i] = display[i] / display['КоличествоТоваровВыкупленные']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "standard-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.Группа3.unique():\n",
    "    display[i] = i\n",
    "    display = display.merge(group3['КоличествоПроданоКлиенту'], left_on=['Id', i], right_on=['Телефон_new', 'Группа3'], how='left')\n",
    "    display = display.drop(columns=[i])\n",
    "    display = display.rename(columns={'КоличествоПроданоКлиенту':i})\n",
    "    display = display.fillna(0)\n",
    "    display[i] = display[i] / display['КоличествоТоваровВыкупленные']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "reported-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = display.merge(df_bought[['Телефон_new', 'Гео']].drop_duplicates(subset = 'Телефон_new'), left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.drop(columns=['Телефон_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "latter-mozambique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>КоличествоЧеков</th>\n",
       "      <th>СреднийЧек</th>\n",
       "      <th>СреднееЧислоТоваровЧека</th>\n",
       "      <th>Выручка</th>\n",
       "      <th>КоличествоТоваров</th>\n",
       "      <th>СредняяМаржа</th>\n",
       "      <th>КоличествоЧековВыкупленные</th>\n",
       "      <th>СреднийЧекВыкупленные</th>\n",
       "      <th>СреднееЧислоТоваровЧекаВыкупленные</th>\n",
       "      <th>...</th>\n",
       "      <th>БИЖУТЕРИЯ</th>\n",
       "      <th>СВЕТООТРАЖАЮЩИЕ ЭЛЕМЕНТЫ</th>\n",
       "      <th>ВЕТАПТЕКА</th>\n",
       "      <th>ВИТАМИНЫ/БАДЫ</th>\n",
       "      <th>ТОВАРЫ ДЛЯ ЧЕРЕПАХ И РЕПТИЛИЙ</th>\n",
       "      <th>ТОВАРЫ ДЛЯ ХОРЬКОВ</th>\n",
       "      <th>ЗЕРКАЛА</th>\n",
       "      <th>ГЛАДИЛЬНЫЕ ДОСКИ,СУШИЛКИ</th>\n",
       "      <th>ТЕХНИКА ДЛЯ ДОМА</th>\n",
       "      <th>Гео</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>1</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>13</td>\n",
       "      <td>38.249231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55575656-49565651494970</td>\n",
       "      <td>1</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.941818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55575155-54535648525672</td>\n",
       "      <td>4</td>\n",
       "      <td>15147.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>85842.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2365.939091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17498.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55575456-55545450525776</td>\n",
       "      <td>2</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>5264.0</td>\n",
       "      <td>9</td>\n",
       "      <td>192.295000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55575054-54575350505479</td>\n",
       "      <td>3</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>76.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123872</th>\n",
       "      <td>55574954-52495355555471</td>\n",
       "      <td>1</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>7</td>\n",
       "      <td>222.321429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123873</th>\n",
       "      <td>55575649-57495654575771</td>\n",
       "      <td>1</td>\n",
       "      <td>578.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123874</th>\n",
       "      <td>55575048-54515157545679</td>\n",
       "      <td>1</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1</td>\n",
       "      <td>435.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123875</th>\n",
       "      <td>55575054-56575557485677</td>\n",
       "      <td>1</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.480000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123876</th>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>1</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-106.286667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123877 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Id  КоличествоЧеков  СреднийЧек  \\\n",
       "0       55574948-52495050484877                1      1634.0   \n",
       "1       55575656-49565651494970                1      1915.0   \n",
       "2       55575155-54535648525672                4     15147.0   \n",
       "3       55575456-55545450525776                2      2782.0   \n",
       "4       55575054-54575350505479                3       599.0   \n",
       "...                         ...              ...         ...   \n",
       "123872  55574954-52495355555471                1      6453.0   \n",
       "123873  55575649-57495654575771                1       578.0   \n",
       "123874  55575048-54515157545679                1      1058.0   \n",
       "123875  55575054-56575557485677                1      1059.0   \n",
       "123876  55574851-50565452485270                1      1232.0   \n",
       "\n",
       "        СреднееЧислоТоваровЧека  Выручка  КоличествоТоваров  СредняяМаржа  \\\n",
       "0                         1.000   1585.0                 13     38.249231   \n",
       "1                         1.000   1816.0                 11     -0.941818   \n",
       "2                         1.000  85842.0                 11   2365.939091   \n",
       "3                         1.125   5264.0                  9    192.295000   \n",
       "4                         1.000   1650.0                  5     76.240000   \n",
       "...                         ...      ...                ...           ...   \n",
       "123872                    1.000   6453.0                  7    222.321429   \n",
       "123873                    1.000    479.0                  2     19.640000   \n",
       "123874                    1.000    909.0                  1    435.070000   \n",
       "123875                    1.000   1059.0                  1     41.480000   \n",
       "123876                    1.000   1232.0                  3   -106.286667   \n",
       "\n",
       "        КоличествоЧековВыкупленные  СреднийЧекВыкупленные  \\\n",
       "0                              1.0                 1585.0   \n",
       "1                              1.0                 1816.0   \n",
       "2                              3.0                17498.0   \n",
       "3                              2.0                 2632.0   \n",
       "4                              1.0                  310.0   \n",
       "...                            ...                    ...   \n",
       "123872                         1.0                 1018.0   \n",
       "123873                         1.0                  479.0   \n",
       "123874                         1.0                  909.0   \n",
       "123875                         1.0                 1059.0   \n",
       "123876                         1.0                 1232.0   \n",
       "\n",
       "        СреднееЧислоТоваровЧекаВыкупленные  ...  БИЖУТЕРИЯ  \\\n",
       "0                                 1.000000  ...        0.0   \n",
       "1                                 1.000000  ...        0.0   \n",
       "2                                 0.545455  ...        0.0   \n",
       "3                                 1.125000  ...        0.0   \n",
       "4                                 0.200000  ...        0.0   \n",
       "...                                    ...  ...        ...   \n",
       "123872                            0.285714  ...        0.0   \n",
       "123873                            1.000000  ...        0.0   \n",
       "123874                            1.000000  ...        0.0   \n",
       "123875                            1.000000  ...        0.0   \n",
       "123876                            1.000000  ...        0.0   \n",
       "\n",
       "        СВЕТООТРАЖАЮЩИЕ ЭЛЕМЕНТЫ  ВЕТАПТЕКА  ВИТАМИНЫ/БАДЫ  \\\n",
       "0                            0.0        0.0            0.0   \n",
       "1                            0.0        0.0            0.0   \n",
       "2                            0.0        0.0            0.0   \n",
       "3                            0.0        0.0            0.0   \n",
       "4                            0.0        0.0            0.0   \n",
       "...                          ...        ...            ...   \n",
       "123872                       0.0        0.0            0.0   \n",
       "123873                       0.0        0.0            0.0   \n",
       "123874                       0.0        0.0            0.0   \n",
       "123875                       0.0        0.0            0.0   \n",
       "123876                       0.0        0.0            0.0   \n",
       "\n",
       "        ТОВАРЫ ДЛЯ ЧЕРЕПАХ И РЕПТИЛИЙ  ТОВАРЫ ДЛЯ ХОРЬКОВ  ЗЕРКАЛА  \\\n",
       "0                                 0.0                 0.0      0.0   \n",
       "1                                 0.0                 0.0      0.0   \n",
       "2                                 0.0                 0.0      0.0   \n",
       "3                                 0.0                 0.0      0.0   \n",
       "4                                 0.0                 0.0      0.0   \n",
       "...                               ...                 ...      ...   \n",
       "123872                            0.0                 0.0      0.0   \n",
       "123873                            0.0                 0.0      0.0   \n",
       "123874                            0.0                 0.0      0.0   \n",
       "123875                            0.0                 0.0      0.0   \n",
       "123876                            0.0                 0.0      0.0   \n",
       "\n",
       "        ГЛАДИЛЬНЫЕ ДОСКИ,СУШИЛКИ  ТЕХНИКА ДЛЯ ДОМА      Гео  \n",
       "0                            0.0               0.0   Москва  \n",
       "1                            0.0               0.0  Регионы  \n",
       "2                            0.0               0.0  Регионы  \n",
       "3                            0.0               0.0   Москва  \n",
       "4                            0.0               0.0   Москва  \n",
       "...                          ...               ...      ...  \n",
       "123872                       0.0               0.0   Москва  \n",
       "123873                       0.0               0.0  Регионы  \n",
       "123874                       0.0               0.0  Регионы  \n",
       "123875                       0.0               0.0   Москва  \n",
       "123876                       0.0               0.0   Москва  \n",
       "\n",
       "[123877 rows x 129 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "increased-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-213-773b91c8539a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_last['Цель'] = 1\n"
     ]
    }
   ],
   "source": [
    "df_last['Цель'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "disabled-flooring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Дата</th>\n",
       "      <th>ДатаДоставки</th>\n",
       "      <th>НомерЗаказаНаСайте</th>\n",
       "      <th>НовыйСтатус</th>\n",
       "      <th>СуммаЗаказаНаСайте</th>\n",
       "      <th>СуммаДокумента</th>\n",
       "      <th>МетодДоставки</th>\n",
       "      <th>ФормаОплаты</th>\n",
       "      <th>Регион</th>\n",
       "      <th>Группа2</th>\n",
       "      <th>...</th>\n",
       "      <th>ДатаЗаказаНаСайте</th>\n",
       "      <th>Телефон_new</th>\n",
       "      <th>ЭлектроннаяПочта_new</th>\n",
       "      <th>Клиент</th>\n",
       "      <th>ID_SKU</th>\n",
       "      <th>ГородМагазина</th>\n",
       "      <th>МагазинЗаказа</th>\n",
       "      <th>Доставка</th>\n",
       "      <th>Id</th>\n",
       "      <th>Цель</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55250</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>12.07.2017 0:00</td>\n",
       "      <td>5089178_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>1 424</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ИГРУШКИ</td>\n",
       "      <td>...</td>\n",
       "      <td>09.07.2017 0:00</td>\n",
       "      <td>55574953-50505455515178</td>\n",
       "      <td>103117_gu15@inbox.ru</td>\n",
       "      <td>Евгения</td>\n",
       "      <td>IDL00028166149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-50505455515178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55251</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>12.07.2017 0:00</td>\n",
       "      <td>5089178_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>1 424</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ОБУВЬ</td>\n",
       "      <td>...</td>\n",
       "      <td>09.07.2017 0:00</td>\n",
       "      <td>55574953-50505455515178</td>\n",
       "      <td>103117_gu15@inbox.ru</td>\n",
       "      <td>Евгения</td>\n",
       "      <td>IDL00040237452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-50505455515178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55252</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>24.07.2017 0:00</td>\n",
       "      <td>5089184_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>1 312</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>КАНЦТОВАРЫ, КНИГИ, ДИСКИ</td>\n",
       "      <td>...</td>\n",
       "      <td>09.07.2017 0:00</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>101109_em20@gmail.com</td>\n",
       "      <td>Гость</td>\n",
       "      <td>ID10013106654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55253</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>24.07.2017 0:00</td>\n",
       "      <td>5089184_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>1 312</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>ИГРУШКИ</td>\n",
       "      <td>...</td>\n",
       "      <td>09.07.2017 0:00</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>101109_em20@gmail.com</td>\n",
       "      <td>Гость</td>\n",
       "      <td>ID9010015025654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55254</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>24.07.2017 0:00</td>\n",
       "      <td>5089184_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>1 312</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>КАНЦТОВАРЫ, КНИГИ, ДИСКИ</td>\n",
       "      <td>...</td>\n",
       "      <td>09.07.2017 0:00</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>101109_em20@gmail.com</td>\n",
       "      <td>Гость</td>\n",
       "      <td>IDL00026684957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55575048-52545652554976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938617</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>02.11.2017 0:00</td>\n",
       "      <td>6005071_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3 222</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>КОСМЕТИКА/ГИГИЕНА</td>\n",
       "      <td>...</td>\n",
       "      <td>31.10.2017 0:00</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>109117_mu19@inbox.ru</td>\n",
       "      <td>Мария</td>\n",
       "      <td>IDL00048117048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938618</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>02.11.2017 0:00</td>\n",
       "      <td>6005071_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3 222</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>КОСМЕТИКА/ГИГИЕНА</td>\n",
       "      <td>...</td>\n",
       "      <td>31.10.2017 0:00</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>109117_mu19@inbox.ru</td>\n",
       "      <td>Мария</td>\n",
       "      <td>IDL00039537957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938619</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>02.11.2017 0:00</td>\n",
       "      <td>6005071_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3 222</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>КОСМЕТИКА/ГИГИЕНА</td>\n",
       "      <td>...</td>\n",
       "      <td>31.10.2017 0:00</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>109117_mu19@inbox.ru</td>\n",
       "      <td>Мария</td>\n",
       "      <td>IDL00039538654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938620</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>02.11.2017 0:00</td>\n",
       "      <td>6005071_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3 222</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>КОСМЕТИКА/ГИГИЕНА</td>\n",
       "      <td>...</td>\n",
       "      <td>31.10.2017 0:00</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>109117_mu19@inbox.ru</td>\n",
       "      <td>Мария</td>\n",
       "      <td>IDL00039538755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574953-52575355515475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938621</th>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>03.11.2017 0:00</td>\n",
       "      <td>6005101_ES</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>848.0</td>\n",
       "      <td>848</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТОВАРЫ ДЛЯ ЖИВОТНЫХ</td>\n",
       "      <td>...</td>\n",
       "      <td>31.10.2017 0:00</td>\n",
       "      <td>55575054-56564948515679</td>\n",
       "      <td>112109_pm21@gmail.com</td>\n",
       "      <td>Иванов</td>\n",
       "      <td>IDL00032748755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55575054-56564948515679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189848 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Дата     ДатаДоставки НомерЗаказаНаСайте НовыйСтатус  \\\n",
       "55250  2017-10-07  12.07.2017 0:00         5089178_TR   Доставлен   \n",
       "55251  2017-10-07  12.07.2017 0:00         5089178_TR   Доставлен   \n",
       "55252  2017-10-07  24.07.2017 0:00         5089184_TR   Доставлен   \n",
       "55253  2017-10-07  24.07.2017 0:00         5089184_TR   Доставлен   \n",
       "55254  2017-10-07  24.07.2017 0:00         5089184_TR   Доставлен   \n",
       "...           ...              ...                ...         ...   \n",
       "938617 2017-10-31  02.11.2017 0:00         6005071_ES  К отгрузке   \n",
       "938618 2017-10-31  02.11.2017 0:00         6005071_ES  К отгрузке   \n",
       "938619 2017-10-31  02.11.2017 0:00         6005071_ES  К отгрузке   \n",
       "938620 2017-10-31  02.11.2017 0:00         6005071_ES  К отгрузке   \n",
       "938621 2017-10-31  03.11.2017 0:00         6005101_ES   Доставлен   \n",
       "\n",
       "        СуммаЗаказаНаСайте СуммаДокумента МетодДоставки  ФормаОплаты   Регион  \\\n",
       "55250               1424.0          1 424      Магазины  Безналичная   Москва   \n",
       "55251               1424.0          1 424      Магазины  Безналичная   Москва   \n",
       "55252               1834.0          1 312      Магазины  Безналичная  Воронеж   \n",
       "55253               1834.0          1 312      Магазины  Безналичная  Воронеж   \n",
       "55254               1834.0          1 312      Магазины  Безналичная  Воронеж   \n",
       "...                    ...            ...           ...          ...      ...   \n",
       "938617              3222.0          3 222    Курьерская     Наличная   Москва   \n",
       "938618              3222.0          3 222    Курьерская     Наличная   Москва   \n",
       "938619              3222.0          3 222    Курьерская     Наличная   Москва   \n",
       "938620              3222.0          3 222    Курьерская     Наличная   Москва   \n",
       "938621               848.0            848      Магазины  Безналичная   Москва   \n",
       "\n",
       "                         Группа2  ... ДатаЗаказаНаСайте  \\\n",
       "55250                    ИГРУШКИ  ...   09.07.2017 0:00   \n",
       "55251                      ОБУВЬ  ...   09.07.2017 0:00   \n",
       "55252   КАНЦТОВАРЫ, КНИГИ, ДИСКИ  ...   09.07.2017 0:00   \n",
       "55253                    ИГРУШКИ  ...   09.07.2017 0:00   \n",
       "55254   КАНЦТОВАРЫ, КНИГИ, ДИСКИ  ...   09.07.2017 0:00   \n",
       "...                          ...  ...               ...   \n",
       "938617         КОСМЕТИКА/ГИГИЕНА  ...   31.10.2017 0:00   \n",
       "938618         КОСМЕТИКА/ГИГИЕНА  ...   31.10.2017 0:00   \n",
       "938619         КОСМЕТИКА/ГИГИЕНА  ...   31.10.2017 0:00   \n",
       "938620         КОСМЕТИКА/ГИГИЕНА  ...   31.10.2017 0:00   \n",
       "938621       ТОВАРЫ ДЛЯ ЖИВОТНЫХ  ...   31.10.2017 0:00   \n",
       "\n",
       "                    Телефон_new   ЭлектроннаяПочта_new   Клиент  \\\n",
       "55250   55574953-50505455515178   103117_gu15@inbox.ru  Евгения   \n",
       "55251   55574953-50505455515178   103117_gu15@inbox.ru  Евгения   \n",
       "55252   55575048-52545652554976  101109_em20@gmail.com    Гость   \n",
       "55253   55575048-52545652554976  101109_em20@gmail.com    Гость   \n",
       "55254   55575048-52545652554976  101109_em20@gmail.com    Гость   \n",
       "...                         ...                    ...      ...   \n",
       "938617  55574953-52575355515475   109117_mu19@inbox.ru    Мария   \n",
       "938618  55574953-52575355515475   109117_mu19@inbox.ru    Мария   \n",
       "938619  55574953-52575355515475   109117_mu19@inbox.ru    Мария   \n",
       "938620  55574953-52575355515475   109117_mu19@inbox.ru    Мария   \n",
       "938621  55575054-56564948515679  112109_pm21@gmail.com   Иванов   \n",
       "\n",
       "                 ID_SKU ГородМагазина МагазинЗаказа  Доставка  \\\n",
       "55250    IDL00028166149             0             0       1.0   \n",
       "55251    IDL00040237452             0             0       1.0   \n",
       "55252     ID10013106654             0             0       1.0   \n",
       "55253   ID9010015025654             0             0       1.0   \n",
       "55254    IDL00026684957             0             0       1.0   \n",
       "...                 ...           ...           ...       ...   \n",
       "938617   IDL00048117048             0             0       1.0   \n",
       "938618   IDL00039537957             0             0       1.0   \n",
       "938619   IDL00039538654             0             0       1.0   \n",
       "938620   IDL00039538755             0             0       1.0   \n",
       "938621   IDL00032748755             0             0       0.0   \n",
       "\n",
       "                             Id  Цель  \n",
       "55250   55574953-50505455515178     1  \n",
       "55251   55574953-50505455515178     1  \n",
       "55252   55575048-52545652554976     1  \n",
       "55253   55575048-52545652554976     1  \n",
       "55254   55575048-52545652554976     1  \n",
       "...                         ...   ...  \n",
       "938617  55574953-52575355515475     1  \n",
       "938618  55574953-52575355515475     1  \n",
       "938619  55574953-52575355515475     1  \n",
       "938620  55574953-52575355515475     1  \n",
       "938621  55575054-56564948515679     1  \n",
       "\n",
       "[189848 rows x 41 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "employed-minutes",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Цель'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-293-d93f01082902>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_last\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Телефон_new'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Цель'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Телефон_new'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Телефон_new'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Цель'] not in index\""
     ]
    }
   ],
   "source": [
    "display = display.merge(df_last[['Телефон_new', 'Цель']], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.drop(columns=['Телефон_new'])\n",
    "display = display.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "architectural-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor # Import Decision Tree Classifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "removable-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = display.drop(columns = ['Id', 'Гео', 'Цель']).values\n",
    "y = display.Цель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "studied-proxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0.0\n",
       "1             0.0\n",
       "2             0.0\n",
       "3             0.0\n",
       "4             0.0\n",
       "            ...  \n",
       "1816140       0.0\n",
       "1816141       0.0\n",
       "1816142       0.0\n",
       "1816143    1059.0\n",
       "1816144       0.0\n",
       "Name: Цель, Length: 1816145, dtype: float64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "protecting-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_model = display\n",
    "display_model.to_csv('display_model.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "russian-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = preprocessing.StandardScaler().fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "atmospheric-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth = 20, min_samples_split = 5, min_samples_leaf = 1)\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "together-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(max_depth = 9, min_samples_split = 5, min_samples_leaf = 1)\n",
    "clf = clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "third-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 0.8488614566713917\n",
      "Accuracy_test: 0.8430183235049442\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.roc_auc_score(y_train, clf.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "injured-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-82583d321b85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy_train:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy_test:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1272\u001b[0m                          str(average_options))\n\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.f1_score(y_train, clf.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy_train:\",metrics.accuracy_score(y_train, clf.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "specific-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 744.0784530292891\n",
      "Accuracy_test: 783.7056155081259\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_squared_error(y_train, clf.predict(x_train), squared = False))\n",
    "print(\"Accuracy_test:\",metrics.mean_squared_error(y_test, y_pred, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "liable-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 405.154367732041\n",
      "Accuracy_test: 577.0381898080705\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_absolute_error(y_train, clf.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tender-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(max_depth = 9, min_samples_split = 5, min_samples_leaf = 1), x, y, cv=3, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "secondary-storage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7925464898984264"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "judicial-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = {'criterion':['gini'], 'min_depth':range(1, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "frozen-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter min_depth for estimator DecisionTreeClassifier(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 581, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 230, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter min_depth for estimator DecisionTreeClassifier(). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-20273d858088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter min_depth for estimator DecisionTreeClassifier(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid = shuffle, cv = 5, verbose = 1, n_jobs = -1)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "random-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "completed-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                                                           | 0/30 [00:27<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                                                           | 0/30 [00:50<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                                                           | 0/30 [01:13<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:39:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  0%|                                                                           | 0/30 [01:35<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:39:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.7981576821031853                                                                                                     \n",
      "  3%|█▌                                           | 1/30 [02:20<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|█▌                                           | 1/30 [02:21<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|█▌                                           | 1/30 [02:55<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|█▌                                           | 1/30 [03:23<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|█▌                                           | 1/30 [03:51<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  3%|█▌                                           | 1/30 [04:18<1:07:44, 140.14s/trial, best loss: 0.20184231789681473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9063131840577441                                                                                                     \n",
      "  7%|███                                          | 2/30 [05:14<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:42:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|███                                          | 2/30 [05:14<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|███                                          | 2/30 [05:21<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|███                                          | 2/30 [05:26<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|███                                          | 2/30 [05:31<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  7%|███                                          | 2/30 [05:36<1:14:44, 160.15s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8275200337267723                                                                                                     \n",
      " 10%|████▋                                          | 3/30 [05:46<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████▋                                          | 3/30 [05:46<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████▋                                          | 3/30 [06:06<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████▋                                          | 3/30 [06:23<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████▋                                          | 3/30 [06:39<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 10%|████▋                                          | 3/30 [06:56<45:45, 101.68s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:44:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8541545444930355                                                                                                     \n",
      " 13%|██████▎                                        | 4/30 [07:29<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██████▎                                        | 4/30 [07:29<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██████▎                                        | 4/30 [07:55<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██████▎                                        | 4/30 [08:16<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██████▎                                        | 4/30 [08:38<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 13%|██████▎                                        | 4/30 [09:00<44:13, 102.05s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8814058862932468                                                                                                     \n",
      " 17%|███████▊                                       | 5/30 [09:41<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███████▊                                       | 5/30 [09:41<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███████▊                                       | 5/30 [10:04<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███████▊                                       | 5/30 [10:24<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███████▊                                       | 5/30 [10:43<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 17%|███████▊                                       | 5/30 [11:02<47:05, 113.01s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:49:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8500901337141382                                                                                                     \n",
      " 20%|█████████▍                                     | 6/30 [11:39<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:49:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████▍                                     | 6/30 [11:40<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:49:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████▍                                     | 6/30 [12:04<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████▍                                     | 6/30 [12:22<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████▍                                     | 6/30 [12:41<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 20%|█████████▍                                     | 6/30 [13:00<45:57, 114.88s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8342095139741256                                                                                                     \n",
      " 23%|██████████▉                                    | 7/30 [13:38<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|██████████▉                                    | 7/30 [13:39<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|██████████▉                                    | 7/30 [14:03<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|██████████▉                                    | 7/30 [14:23<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|██████████▉                                    | 7/30 [14:43<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:52:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 23%|██████████▉                                    | 7/30 [15:03<44:29, 116.07s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8629276239276032                                                                                                     \n",
      " 27%|████████████▌                                  | 8/30 [15:43<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|████████████▌                                  | 8/30 [15:43<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|████████████▌                                  | 8/30 [15:54<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|████████████▌                                  | 8/30 [16:03<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|████████████▌                                  | 8/30 [16:11<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 27%|████████████▌                                  | 8/30 [16:20<43:36, 118.93s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.778781527804094                                                                                                      \n",
      " 30%|██████████████▍                                 | 9/30 [16:36<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:54:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████▍                                 | 9/30 [16:36<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████▍                                 | 9/30 [17:20<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████▍                                 | 9/30 [17:55<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████▍                                 | 9/30 [18:30<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 30%|██████████████▍                                 | 9/30 [19:06<34:23, 98.24s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8673758294141978                                                                                                     \n",
      " 33%|███████████████▎                              | 10/30 [20:15<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|███████████████▎                              | 10/30 [20:16<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:58:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|███████████████▎                              | 10/30 [21:12<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:59:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|███████████████▎                              | 10/30 [21:57<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|███████████████▎                              | 10/30 [22:43<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 33%|███████████████▎                              | 10/30 [23:27<45:14, 135.70s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8913578544387434                                                                                                     \n",
      " 37%|████████████████▊                             | 11/30 [24:57<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|████████████████▊                             | 11/30 [24:58<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|████████████████▊                             | 11/30 [25:08<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|████████████████▊                             | 11/30 [25:16<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|████████████████▊                             | 11/30 [25:24<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 37%|████████████████▊                             | 11/30 [25:33<57:07, 180.41s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8577391551052671                                                                                                     \n",
      " 40%|██████████████████▍                           | 12/30 [25:49<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|██████████████████▍                           | 12/30 [25:50<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|██████████████████▍                           | 12/30 [25:55<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|██████████████████▍                           | 12/30 [25:59<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|██████████████████▍                           | 12/30 [26:03<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 40%|██████████████████▍                           | 12/30 [26:06<42:25, 141.44s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8265056623852652                                                                                                     \n",
      " 43%|███████████████████▉                          | 13/30 [26:14<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:03:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|███████████████████▉                          | 13/30 [26:14<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|███████████████████▉                          | 13/30 [26:21<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|███████████████████▉                          | 13/30 [26:27<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|███████████████████▉                          | 13/30 [26:32<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 43%|███████████████████▉                          | 13/30 [26:38<30:01, 105.94s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8074859271547095                                                                                                     \n",
      " 47%|█████████████████████▉                         | 14/30 [26:49<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:04:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████████████████▉                         | 14/30 [26:49<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████████████████▉                         | 14/30 [27:29<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████████████████▉                         | 14/30 [28:01<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:06:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████████████████▉                         | 14/30 [28:34<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:06:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 47%|█████████████████████▉                         | 14/30 [29:06<22:32, 84.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8771975704378612                                                                                                     \n",
      " 50%|███████████████████████                       | 15/30 [30:13<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|███████████████████████                       | 15/30 [30:13<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|███████████████████████                       | 15/30 [30:33<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|███████████████████████                       | 15/30 [30:48<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|███████████████████████                       | 15/30 [31:03<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 50%|███████████████████████                       | 15/30 [31:19<30:08, 120.56s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:17] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8227702377252196                                                                                                     \n",
      " 53%|████████████████████████▌                     | 16/30 [31:49<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|████████████████████████▌                     | 16/30 [31:49<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|████████████████████████▌                     | 16/30 [31:54<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|████████████████████████▌                     | 16/30 [31:57<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|████████████████████████▌                     | 16/30 [32:01<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 53%|████████████████████████▌                     | 16/30 [32:05<26:22, 113.06s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.7770885862595815                                                                                                     \n",
      " 57%|██████████████████████████▋                    | 17/30 [32:13<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|██████████████████████████▋                    | 17/30 [32:13<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|██████████████████████████▋                    | 17/30 [32:18<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|██████████████████████████▋                    | 17/30 [32:22<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|██████████████████████████▋                    | 17/30 [32:26<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 57%|██████████████████████████▋                    | 17/30 [32:30<18:42, 86.38s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8542367883803574                                                                                                     \n",
      " 60%|████████████████████████████▏                  | 18/30 [32:38<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████▏                  | 18/30 [32:38<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████▏                  | 18/30 [32:43<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████▏                  | 18/30 [32:46<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████▏                  | 18/30 [32:50<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 60%|████████████████████████████▏                  | 18/30 [32:53<13:35, 67.98s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.7978629455978226                                                                                                     \n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:00<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:00<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:17<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:13] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:30<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:42<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 63%|█████████████████████████████▊                 | 19/30 [33:55<09:55, 54.17s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8280820608694585                                                                                                     \n",
      " 67%|███████████████████████████████▎               | 20/30 [34:21<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|███████████████████████████████▎               | 20/30 [34:22<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|███████████████████████████████▎               | 20/30 [35:08<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|███████████████████████████████▎               | 20/30 [35:46<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|███████████████████████████████▎               | 20/30 [36:23<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 67%|███████████████████████████████▎               | 20/30 [37:03<10:21, 62.19s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9054084653606868                                                                                                     \n",
      " 70%|████████████████████████████████▏             | 21/30 [38:17<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████▏             | 21/30 [38:18<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:17:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████▏             | 21/30 [39:29<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:18:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████▏             | 21/30 [40:24<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:19:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████▏             | 21/30 [41:19<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:19:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 70%|████████████████████████████████▏             | 21/30 [42:12<17:10, 114.51s/trial, best loss: 0.09368681594225592]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9078690360151768                                                                                                     \n",
      " 73%|█████████████████████████████████▋            | 22/30 [44:01<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|█████████████████████████████████▋            | 22/30 [44:02<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|█████████████████████████████████▋            | 22/30 [44:24<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|█████████████████████████████████▋            | 22/30 [44:41<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|█████████████████████████████████▋            | 22/30 [44:59<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 73%|█████████████████████████████████▋            | 22/30 [45:17<24:26, 183.31s/trial, best loss: 0.09213096398482323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9128792803884169                                                                                                     \n",
      " 77%|███████████████████████████████████▎          | 23/30 [45:52<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|███████████████████████████████████▎          | 23/30 [45:52<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|███████████████████████████████████▎          | 23/30 [46:05<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|███████████████████████████████████▎          | 23/30 [46:16<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|███████████████████████████████████▎          | 23/30 [46:27<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:20] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 77%|███████████████████████████████████▎          | 23/30 [46:37<18:50, 161.53s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.7985620792388899                                                                                                     \n",
      " 80%|████████████████████████████████████▊         | 24/30 [46:58<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████████████████████████▊         | 24/30 [46:59<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████████████████████████▊         | 24/30 [47:02<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████████████████████████▊         | 24/30 [47:04<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████████████████████████▊         | 24/30 [47:07<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 80%|████████████████████████████████████▊         | 24/30 [47:10<13:18, 133.05s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.7910227053248686                                                                                                     \n",
      " 83%|███████████████████████████████████████▏       | 25/30 [47:14<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [47:15<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [48:05<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:26:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [48:44<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [49:23<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [50:01<08:09, 97.91s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:28:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9043187060204867                                                                                                     \n",
      " 87%|███████████████████████████████████████▊      | 26/30 [51:18<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|███████████████████████████████████████▊      | 26/30 [51:18<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|███████████████████████████████████████▊      | 26/30 [51:33<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|███████████████████████████████████████▊      | 26/30 [51:45<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|███████████████████████████████████████▊      | 26/30 [51:57<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 87%|███████████████████████████████████████▊      | 26/30 [52:09<09:26, 141.65s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.8063618571324319                                                                                                     \n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [52:32<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:16] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [52:32<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [52:44<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [52:53<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [53:02<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 90%|█████████████████████████████████████████▍    | 27/30 [53:11<06:03, 121.25s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:31:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9045106067800838                                                                                                     \n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [53:30<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:31:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [53:30<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [54:22<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [55:02<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [55:42<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:34:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 93%|██████████████████████████████████████████▉   | 28/30 [56:21<03:24, 102.22s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:34:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9110835644016069                                                                                                     \n",
      " 97%|████████████████████████████████████████████▍ | 29/30 [57:44<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:35:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████████████████████████████▍ | 29/30 [57:45<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:36:18] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████████████████████████████▍ | 29/30 [58:35<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████████████████████████████▍ | 29/30 [59:17<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|████████████████████████████████████████████▍ | 29/30 [59:59<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:26] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " 97%|██████████████████████████████████████████▌ | 29/30 [1:00:42<02:27, 147.83s/trial, best loss: 0.08712071961158308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CrossValMean:                                                                                                          \n",
      "0.9101102832950703                                                                                                     \n",
      "100%|████████████████████████████████████████████| 30/30 [1:02:05<00:00, 124.19s/trial, best loss: 0.08712071961158308]\n",
      "Best:  {'colsample_bytree': 0.59, 'gamma': 0.09, 'learning_rate': 0.32, 'max_depth': 22, 'min_child_weight': 1.0, 'n_estimators': 9, 'subsample': 0.92}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    classifier = XGBClassifier(n_estimators = space['n_estimators'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            learning_rate = space['learning_rate'],\n",
    "                            gamma = space['gamma'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree = space['colsample_bytree']\n",
    "                            )\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 5)\n",
    "    CrossValMean = accuracies.mean()\n",
    "\n",
    "    print(\"CrossValMean:\", CrossValMean)\n",
    "\n",
    "    return{'loss':1-CrossValMean, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'n_estimators' : hp.choice('n_estimators', range(20, 205, 5)),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "formal-maria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb = xgboost.XGBClassifier(**best)\n",
    "xgb = xgb.fit(x_train,y_train)\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "earned-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_train: 0.9519174308103779\n",
      "Roc_test: 0.8709382157028542\n"
     ]
    }
   ],
   "source": [
    "print(\"Roc_train:\",metrics.roc_auc_score(y_train, xgb.predict(x_train)))\n",
    "print(\"Roc_test:\",metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "informal-steel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_train: 0.9502787738246051\n",
      "F1_test: 0.8647646652398847\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_train:\",metrics.f1_score(y_train, xgb.predict(x_train)))\n",
    "print(\"F1_test:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "impaired-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini_train: 0.9038348616207559\n",
      "Gini_test: 0.7418764314057085\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini_train:\",2*metrics.roc_auc_score(y_train, xgb.predict(x_train))-1)\n",
    "print(\"Gini_test:\",2*metrics.roc_auc_score(y_test, y_pred)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "anonymous-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 0.9523855216893647\n",
      "Accuracy_test: 0.8716616024308332\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.accuracy_score(y_train, xgb.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "conservative-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(xgboost.XGBClassifier(**best), x, y, cv=3, scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bigger-spain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7678863856480295"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "careful-diabetes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    classifier = XGBClassifier(n_estimators = space['n_estimators'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            learning_rate = space['learning_rate'],\n",
    "                            gamma = space['gamma'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree = space['colsample_bytree']\n",
    "                            )\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "    CrossValMean = accuracies.mean()\n",
    "\n",
    "    print(\"CrossValMean:\", CrossValMean)\n",
    "\n",
    "    return{'loss':1-CrossValMean, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'n_estimators' : hp.choice('n_estimators', range(20, 205, 5)),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "portuguese-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'colsample_bytree': 0.59, 'gamma': 0.09, 'learning_rate': 0.32, 'max_depth': 22, 'min_child_weight': 1.0, 'n_estimators': 9, 'subsample': 0.92}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "medieval-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.094755\n",
      "0:\tlearn: 2697.4198646\ttotal: 188ms\tremaining: 3m 8s\n",
      "1:\tlearn: 2583.0685933\ttotal: 362ms\tremaining: 3m\n",
      "2:\tlearn: 2482.7503348\ttotal: 538ms\tremaining: 2m 58s\n",
      "3:\tlearn: 2392.0352560\ttotal: 710ms\tremaining: 2m 56s\n",
      "4:\tlearn: 2315.7878773\ttotal: 886ms\tremaining: 2m 56s\n",
      "5:\tlearn: 2247.1340722\ttotal: 1.07s\tremaining: 2m 57s\n",
      "6:\tlearn: 2191.0394659\ttotal: 1.26s\tremaining: 2m 58s\n",
      "7:\tlearn: 2141.8438052\ttotal: 1.44s\tremaining: 2m 58s\n",
      "8:\tlearn: 2098.6171672\ttotal: 1.62s\tremaining: 2m 58s\n",
      "9:\tlearn: 2059.9582307\ttotal: 1.8s\tremaining: 2m 58s\n",
      "10:\tlearn: 2024.5626268\ttotal: 1.99s\tremaining: 2m 59s\n",
      "11:\tlearn: 1994.3926220\ttotal: 2.17s\tremaining: 2m 58s\n",
      "12:\tlearn: 1961.9449031\ttotal: 2.36s\tremaining: 2m 59s\n",
      "13:\tlearn: 1939.6888158\ttotal: 2.56s\tremaining: 3m\n",
      "14:\tlearn: 1920.0348960\ttotal: 2.76s\tremaining: 3m 1s\n",
      "15:\tlearn: 1896.7664238\ttotal: 2.94s\tremaining: 3m\n",
      "16:\tlearn: 1879.3194734\ttotal: 3.13s\tremaining: 3m 1s\n",
      "17:\tlearn: 1865.0313383\ttotal: 3.32s\tremaining: 3m 1s\n",
      "18:\tlearn: 1849.7819766\ttotal: 3.51s\tremaining: 3m 1s\n",
      "19:\tlearn: 1836.9079111\ttotal: 3.69s\tremaining: 3m\n",
      "20:\tlearn: 1823.9814559\ttotal: 3.87s\tremaining: 3m\n",
      "21:\tlearn: 1815.8799865\ttotal: 4.05s\tremaining: 3m\n",
      "22:\tlearn: 1805.7146748\ttotal: 4.24s\tremaining: 2m 59s\n",
      "23:\tlearn: 1796.2302544\ttotal: 4.42s\tremaining: 2m 59s\n",
      "24:\tlearn: 1788.0180355\ttotal: 4.62s\tremaining: 3m\n",
      "25:\tlearn: 1781.6622168\ttotal: 4.81s\tremaining: 3m\n",
      "26:\tlearn: 1776.0721624\ttotal: 5.01s\tremaining: 3m\n",
      "27:\tlearn: 1769.7316731\ttotal: 5.2s\tremaining: 3m\n",
      "28:\tlearn: 1764.5215135\ttotal: 5.39s\tremaining: 3m\n",
      "29:\tlearn: 1759.3565971\ttotal: 5.58s\tremaining: 3m\n",
      "30:\tlearn: 1754.9542622\ttotal: 5.77s\tremaining: 3m\n",
      "31:\tlearn: 1750.2984548\ttotal: 5.95s\tremaining: 3m\n",
      "32:\tlearn: 1744.0825397\ttotal: 6.14s\tremaining: 3m\n",
      "33:\tlearn: 1741.2148434\ttotal: 6.33s\tremaining: 2m 59s\n",
      "34:\tlearn: 1737.9547911\ttotal: 6.52s\tremaining: 2m 59s\n",
      "35:\tlearn: 1732.7839746\ttotal: 6.7s\tremaining: 2m 59s\n",
      "36:\tlearn: 1727.9949037\ttotal: 6.89s\tremaining: 2m 59s\n",
      "37:\tlearn: 1722.9205495\ttotal: 7.08s\tremaining: 2m 59s\n",
      "38:\tlearn: 1717.2792153\ttotal: 7.28s\tremaining: 2m 59s\n",
      "39:\tlearn: 1713.7004202\ttotal: 7.47s\tremaining: 2m 59s\n",
      "40:\tlearn: 1711.5731990\ttotal: 7.65s\tremaining: 2m 59s\n",
      "41:\tlearn: 1705.7895851\ttotal: 7.84s\tremaining: 2m 58s\n",
      "42:\tlearn: 1702.0468365\ttotal: 8.03s\tremaining: 2m 58s\n",
      "43:\tlearn: 1700.8758506\ttotal: 8.21s\tremaining: 2m 58s\n",
      "44:\tlearn: 1698.1374216\ttotal: 8.4s\tremaining: 2m 58s\n",
      "45:\tlearn: 1694.5477459\ttotal: 8.58s\tremaining: 2m 58s\n",
      "46:\tlearn: 1690.8580294\ttotal: 8.78s\tremaining: 2m 58s\n",
      "47:\tlearn: 1688.3671243\ttotal: 8.96s\tremaining: 2m 57s\n",
      "48:\tlearn: 1686.9109173\ttotal: 9.15s\tremaining: 2m 57s\n",
      "49:\tlearn: 1684.2615509\ttotal: 9.34s\tremaining: 2m 57s\n",
      "50:\tlearn: 1681.8174137\ttotal: 9.53s\tremaining: 2m 57s\n",
      "51:\tlearn: 1676.8087697\ttotal: 9.71s\tremaining: 2m 57s\n",
      "52:\tlearn: 1673.0899541\ttotal: 9.89s\tremaining: 2m 56s\n",
      "53:\tlearn: 1669.6497892\ttotal: 10.1s\tremaining: 2m 56s\n",
      "54:\tlearn: 1666.3661875\ttotal: 10.3s\tremaining: 2m 56s\n",
      "55:\tlearn: 1662.3716880\ttotal: 10.4s\tremaining: 2m 56s\n",
      "56:\tlearn: 1660.7358686\ttotal: 10.6s\tremaining: 2m 55s\n",
      "57:\tlearn: 1658.2011452\ttotal: 10.8s\tremaining: 2m 55s\n",
      "58:\tlearn: 1655.8879678\ttotal: 11s\tremaining: 2m 55s\n",
      "59:\tlearn: 1653.4723835\ttotal: 11.2s\tremaining: 2m 55s\n",
      "60:\tlearn: 1652.4460554\ttotal: 11.4s\tremaining: 2m 55s\n",
      "61:\tlearn: 1651.6246680\ttotal: 11.5s\tremaining: 2m 54s\n",
      "62:\tlearn: 1647.4016113\ttotal: 11.7s\tremaining: 2m 54s\n",
      "63:\tlearn: 1644.0009873\ttotal: 11.9s\tremaining: 2m 54s\n",
      "64:\tlearn: 1639.8654581\ttotal: 12.1s\tremaining: 2m 54s\n",
      "65:\tlearn: 1637.3209843\ttotal: 12.3s\tremaining: 2m 54s\n",
      "66:\tlearn: 1635.9571092\ttotal: 12.5s\tremaining: 2m 53s\n",
      "67:\tlearn: 1632.4380575\ttotal: 12.7s\tremaining: 2m 53s\n",
      "68:\tlearn: 1630.2402972\ttotal: 12.8s\tremaining: 2m 53s\n",
      "69:\tlearn: 1628.6682848\ttotal: 13s\tremaining: 2m 53s\n",
      "70:\tlearn: 1627.6287529\ttotal: 13.2s\tremaining: 2m 53s\n",
      "71:\tlearn: 1626.5139444\ttotal: 13.4s\tremaining: 2m 52s\n",
      "72:\tlearn: 1625.3649869\ttotal: 13.6s\tremaining: 2m 52s\n",
      "73:\tlearn: 1622.0781341\ttotal: 13.8s\tremaining: 2m 52s\n",
      "74:\tlearn: 1621.0185464\ttotal: 13.9s\tremaining: 2m 51s\n",
      "75:\tlearn: 1618.0386172\ttotal: 14.1s\tremaining: 2m 51s\n",
      "76:\tlearn: 1616.6745394\ttotal: 14.3s\tremaining: 2m 51s\n",
      "77:\tlearn: 1613.9567030\ttotal: 14.5s\tremaining: 2m 51s\n",
      "78:\tlearn: 1612.5908160\ttotal: 14.7s\tremaining: 2m 51s\n",
      "79:\tlearn: 1611.0985496\ttotal: 14.8s\tremaining: 2m 50s\n",
      "80:\tlearn: 1609.3940381\ttotal: 15s\tremaining: 2m 50s\n",
      "81:\tlearn: 1607.6541369\ttotal: 15.2s\tremaining: 2m 50s\n",
      "82:\tlearn: 1605.3582631\ttotal: 15.4s\tremaining: 2m 50s\n",
      "83:\tlearn: 1603.7697129\ttotal: 15.6s\tremaining: 2m 49s\n",
      "84:\tlearn: 1602.4253170\ttotal: 15.8s\tremaining: 2m 49s\n",
      "85:\tlearn: 1601.0880846\ttotal: 16s\tremaining: 2m 49s\n",
      "86:\tlearn: 1598.9558378\ttotal: 16.1s\tremaining: 2m 49s\n",
      "87:\tlearn: 1597.3349189\ttotal: 16.3s\tremaining: 2m 49s\n",
      "88:\tlearn: 1593.2630533\ttotal: 16.5s\tremaining: 2m 48s\n",
      "89:\tlearn: 1591.1922171\ttotal: 16.7s\tremaining: 2m 48s\n",
      "90:\tlearn: 1588.5639584\ttotal: 16.9s\tremaining: 2m 48s\n",
      "91:\tlearn: 1587.4413437\ttotal: 17.1s\tremaining: 2m 48s\n",
      "92:\tlearn: 1586.2849992\ttotal: 17.2s\tremaining: 2m 48s\n",
      "93:\tlearn: 1584.2951786\ttotal: 17.4s\tremaining: 2m 47s\n",
      "94:\tlearn: 1581.2302374\ttotal: 17.6s\tremaining: 2m 47s\n",
      "95:\tlearn: 1579.0651737\ttotal: 17.8s\tremaining: 2m 47s\n",
      "96:\tlearn: 1577.2906553\ttotal: 18s\tremaining: 2m 47s\n",
      "97:\tlearn: 1575.8180038\ttotal: 18.2s\tremaining: 2m 47s\n",
      "98:\tlearn: 1574.0239983\ttotal: 18.4s\tremaining: 2m 47s\n",
      "99:\tlearn: 1572.0548541\ttotal: 18.5s\tremaining: 2m 46s\n",
      "100:\tlearn: 1570.2637937\ttotal: 18.7s\tremaining: 2m 46s\n",
      "101:\tlearn: 1567.4922371\ttotal: 18.9s\tremaining: 2m 46s\n",
      "102:\tlearn: 1566.0483330\ttotal: 19.1s\tremaining: 2m 46s\n",
      "103:\tlearn: 1563.8840714\ttotal: 19.3s\tremaining: 2m 46s\n",
      "104:\tlearn: 1560.4153052\ttotal: 19.5s\tremaining: 2m 45s\n",
      "105:\tlearn: 1559.6753264\ttotal: 19.6s\tremaining: 2m 45s\n",
      "106:\tlearn: 1558.3990525\ttotal: 19.8s\tremaining: 2m 45s\n",
      "107:\tlearn: 1557.2651209\ttotal: 20s\tremaining: 2m 45s\n",
      "108:\tlearn: 1555.7571983\ttotal: 20.2s\tremaining: 2m 44s\n",
      "109:\tlearn: 1555.0049425\ttotal: 20.4s\tremaining: 2m 44s\n",
      "110:\tlearn: 1552.8860575\ttotal: 20.5s\tremaining: 2m 44s\n",
      "111:\tlearn: 1551.8852157\ttotal: 20.7s\tremaining: 2m 44s\n",
      "112:\tlearn: 1550.7710095\ttotal: 20.9s\tremaining: 2m 44s\n",
      "113:\tlearn: 1548.6716583\ttotal: 21.1s\tremaining: 2m 43s\n",
      "114:\tlearn: 1546.9739658\ttotal: 21.3s\tremaining: 2m 43s\n",
      "115:\tlearn: 1546.0468793\ttotal: 21.5s\tremaining: 2m 43s\n",
      "116:\tlearn: 1544.5362505\ttotal: 21.6s\tremaining: 2m 43s\n",
      "117:\tlearn: 1543.5371919\ttotal: 21.8s\tremaining: 2m 43s\n",
      "118:\tlearn: 1542.0423676\ttotal: 22s\tremaining: 2m 42s\n",
      "119:\tlearn: 1541.4048471\ttotal: 22.2s\tremaining: 2m 42s\n",
      "120:\tlearn: 1538.8795993\ttotal: 22.4s\tremaining: 2m 42s\n",
      "121:\tlearn: 1537.2678895\ttotal: 22.6s\tremaining: 2m 42s\n",
      "122:\tlearn: 1535.9157939\ttotal: 22.8s\tremaining: 2m 42s\n",
      "123:\tlearn: 1535.0184075\ttotal: 23s\tremaining: 2m 42s\n",
      "124:\tlearn: 1533.9972401\ttotal: 23.1s\tremaining: 2m 42s\n",
      "125:\tlearn: 1532.6353930\ttotal: 23.3s\tremaining: 2m 41s\n",
      "126:\tlearn: 1530.1729824\ttotal: 23.5s\tremaining: 2m 41s\n",
      "127:\tlearn: 1527.9571387\ttotal: 23.7s\tremaining: 2m 41s\n",
      "128:\tlearn: 1526.6943345\ttotal: 23.9s\tremaining: 2m 41s\n",
      "129:\tlearn: 1525.5553581\ttotal: 24.1s\tremaining: 2m 41s\n",
      "130:\tlearn: 1523.2270444\ttotal: 24.3s\tremaining: 2m 41s\n",
      "131:\tlearn: 1522.0668139\ttotal: 24.5s\tremaining: 2m 40s\n",
      "132:\tlearn: 1521.1606563\ttotal: 24.7s\tremaining: 2m 40s\n",
      "133:\tlearn: 1519.8519626\ttotal: 24.9s\tremaining: 2m 40s\n",
      "134:\tlearn: 1518.7060421\ttotal: 25.1s\tremaining: 2m 40s\n",
      "135:\tlearn: 1516.9515330\ttotal: 25.3s\tremaining: 2m 40s\n",
      "136:\tlearn: 1514.8096819\ttotal: 25.4s\tremaining: 2m 40s\n",
      "137:\tlearn: 1514.0710027\ttotal: 25.6s\tremaining: 2m 40s\n",
      "138:\tlearn: 1512.5812147\ttotal: 25.8s\tremaining: 2m 39s\n",
      "139:\tlearn: 1510.7930362\ttotal: 26s\tremaining: 2m 39s\n",
      "140:\tlearn: 1509.9764079\ttotal: 26.2s\tremaining: 2m 39s\n",
      "141:\tlearn: 1508.7388725\ttotal: 26.4s\tremaining: 2m 39s\n",
      "142:\tlearn: 1506.0578736\ttotal: 26.5s\tremaining: 2m 39s\n",
      "143:\tlearn: 1503.6631793\ttotal: 26.7s\tremaining: 2m 38s\n",
      "144:\tlearn: 1502.5511719\ttotal: 26.9s\tremaining: 2m 38s\n",
      "145:\tlearn: 1501.3127111\ttotal: 27.1s\tremaining: 2m 38s\n",
      "146:\tlearn: 1499.6547116\ttotal: 27.3s\tremaining: 2m 38s\n",
      "147:\tlearn: 1498.2748298\ttotal: 27.5s\tremaining: 2m 38s\n",
      "148:\tlearn: 1497.2976560\ttotal: 27.7s\tremaining: 2m 38s\n",
      "149:\tlearn: 1495.7859479\ttotal: 27.9s\tremaining: 2m 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150:\tlearn: 1494.3461367\ttotal: 28s\tremaining: 2m 37s\n",
      "151:\tlearn: 1492.7832949\ttotal: 28.2s\tremaining: 2m 37s\n",
      "152:\tlearn: 1491.7422971\ttotal: 28.4s\tremaining: 2m 37s\n",
      "153:\tlearn: 1489.9647362\ttotal: 28.6s\tremaining: 2m 37s\n",
      "154:\tlearn: 1489.1592478\ttotal: 28.8s\tremaining: 2m 36s\n",
      "155:\tlearn: 1487.4561739\ttotal: 29s\tremaining: 2m 36s\n",
      "156:\tlearn: 1485.8088849\ttotal: 29.2s\tremaining: 2m 36s\n",
      "157:\tlearn: 1484.1889033\ttotal: 29.3s\tremaining: 2m 36s\n",
      "158:\tlearn: 1482.9497827\ttotal: 29.5s\tremaining: 2m 36s\n",
      "159:\tlearn: 1481.3538681\ttotal: 29.7s\tremaining: 2m 35s\n",
      "160:\tlearn: 1480.3000984\ttotal: 29.9s\tremaining: 2m 35s\n",
      "161:\tlearn: 1479.8086208\ttotal: 30.1s\tremaining: 2m 35s\n",
      "162:\tlearn: 1477.7688016\ttotal: 30.3s\tremaining: 2m 35s\n",
      "163:\tlearn: 1476.0100337\ttotal: 30.5s\tremaining: 2m 35s\n",
      "164:\tlearn: 1475.2949514\ttotal: 30.6s\tremaining: 2m 35s\n",
      "165:\tlearn: 1473.0255135\ttotal: 30.8s\tremaining: 2m 34s\n",
      "166:\tlearn: 1472.2613755\ttotal: 31s\tremaining: 2m 34s\n",
      "167:\tlearn: 1471.8586515\ttotal: 31.2s\tremaining: 2m 34s\n",
      "168:\tlearn: 1470.1255023\ttotal: 31.4s\tremaining: 2m 34s\n",
      "169:\tlearn: 1468.7944630\ttotal: 31.6s\tremaining: 2m 34s\n",
      "170:\tlearn: 1468.1813596\ttotal: 31.8s\tremaining: 2m 34s\n",
      "171:\tlearn: 1466.7046711\ttotal: 32s\tremaining: 2m 34s\n",
      "172:\tlearn: 1465.0397772\ttotal: 32.2s\tremaining: 2m 33s\n",
      "173:\tlearn: 1463.7219592\ttotal: 32.4s\tremaining: 2m 33s\n",
      "174:\tlearn: 1461.9115477\ttotal: 32.6s\tremaining: 2m 33s\n",
      "175:\tlearn: 1461.3002974\ttotal: 32.7s\tremaining: 2m 33s\n",
      "176:\tlearn: 1459.8580180\ttotal: 32.9s\tremaining: 2m 33s\n",
      "177:\tlearn: 1459.3567020\ttotal: 33.1s\tremaining: 2m 32s\n",
      "178:\tlearn: 1458.1997659\ttotal: 33.3s\tremaining: 2m 32s\n",
      "179:\tlearn: 1456.4919839\ttotal: 33.5s\tremaining: 2m 32s\n",
      "180:\tlearn: 1455.5710383\ttotal: 33.7s\tremaining: 2m 32s\n",
      "181:\tlearn: 1454.1312528\ttotal: 33.9s\tremaining: 2m 32s\n",
      "182:\tlearn: 1452.8727642\ttotal: 34.1s\tremaining: 2m 32s\n",
      "183:\tlearn: 1451.4930245\ttotal: 34.2s\tremaining: 2m 31s\n",
      "184:\tlearn: 1450.0964339\ttotal: 34.4s\tremaining: 2m 31s\n",
      "185:\tlearn: 1449.0228868\ttotal: 34.6s\tremaining: 2m 31s\n",
      "186:\tlearn: 1447.6415959\ttotal: 34.8s\tremaining: 2m 31s\n",
      "187:\tlearn: 1446.5562016\ttotal: 35s\tremaining: 2m 31s\n",
      "188:\tlearn: 1445.9440198\ttotal: 35.2s\tremaining: 2m 30s\n",
      "189:\tlearn: 1445.0266954\ttotal: 35.4s\tremaining: 2m 30s\n",
      "190:\tlearn: 1443.7812674\ttotal: 35.6s\tremaining: 2m 30s\n",
      "191:\tlearn: 1442.4953162\ttotal: 35.7s\tremaining: 2m 30s\n",
      "192:\tlearn: 1441.0509221\ttotal: 35.9s\tremaining: 2m 30s\n",
      "193:\tlearn: 1440.2485187\ttotal: 36.1s\tremaining: 2m 29s\n",
      "194:\tlearn: 1439.5423454\ttotal: 36.3s\tremaining: 2m 29s\n",
      "195:\tlearn: 1438.2407640\ttotal: 36.5s\tremaining: 2m 29s\n",
      "196:\tlearn: 1437.3700953\ttotal: 36.7s\tremaining: 2m 29s\n",
      "197:\tlearn: 1436.2866101\ttotal: 36.9s\tremaining: 2m 29s\n",
      "198:\tlearn: 1435.0032127\ttotal: 37.1s\tremaining: 2m 29s\n",
      "199:\tlearn: 1433.6779415\ttotal: 37.3s\tremaining: 2m 29s\n",
      "200:\tlearn: 1432.2385579\ttotal: 37.5s\tremaining: 2m 28s\n",
      "201:\tlearn: 1430.6225399\ttotal: 37.6s\tremaining: 2m 28s\n",
      "202:\tlearn: 1430.0455952\ttotal: 37.8s\tremaining: 2m 28s\n",
      "203:\tlearn: 1428.8663640\ttotal: 38s\tremaining: 2m 28s\n",
      "204:\tlearn: 1428.3845987\ttotal: 38.2s\tremaining: 2m 28s\n",
      "205:\tlearn: 1427.4812606\ttotal: 38.4s\tremaining: 2m 27s\n",
      "206:\tlearn: 1426.9002136\ttotal: 38.6s\tremaining: 2m 27s\n",
      "207:\tlearn: 1425.9901320\ttotal: 38.8s\tremaining: 2m 27s\n",
      "208:\tlearn: 1424.8182667\ttotal: 38.9s\tremaining: 2m 27s\n",
      "209:\tlearn: 1423.4715445\ttotal: 39.1s\tremaining: 2m 27s\n",
      "210:\tlearn: 1422.3307458\ttotal: 39.3s\tremaining: 2m 26s\n",
      "211:\tlearn: 1421.5176836\ttotal: 39.5s\tremaining: 2m 26s\n",
      "212:\tlearn: 1421.0705991\ttotal: 39.7s\tremaining: 2m 26s\n",
      "213:\tlearn: 1420.0294583\ttotal: 39.9s\tremaining: 2m 26s\n",
      "214:\tlearn: 1419.6226022\ttotal: 40.1s\tremaining: 2m 26s\n",
      "215:\tlearn: 1418.5751042\ttotal: 40.3s\tremaining: 2m 26s\n",
      "216:\tlearn: 1417.6170807\ttotal: 40.5s\tremaining: 2m 26s\n",
      "217:\tlearn: 1416.7933242\ttotal: 40.6s\tremaining: 2m 25s\n",
      "218:\tlearn: 1416.4505285\ttotal: 40.8s\tremaining: 2m 25s\n",
      "219:\tlearn: 1415.3380746\ttotal: 41s\tremaining: 2m 25s\n",
      "220:\tlearn: 1414.7070287\ttotal: 41.2s\tremaining: 2m 25s\n",
      "221:\tlearn: 1413.8038186\ttotal: 41.4s\tremaining: 2m 25s\n",
      "222:\tlearn: 1412.9293206\ttotal: 41.6s\tremaining: 2m 24s\n",
      "223:\tlearn: 1412.1705326\ttotal: 41.8s\tremaining: 2m 24s\n",
      "224:\tlearn: 1411.2669322\ttotal: 41.9s\tremaining: 2m 24s\n",
      "225:\tlearn: 1410.2262754\ttotal: 42.1s\tremaining: 2m 24s\n",
      "226:\tlearn: 1409.6400533\ttotal: 42.3s\tremaining: 2m 24s\n",
      "227:\tlearn: 1408.9559875\ttotal: 42.5s\tremaining: 2m 23s\n",
      "228:\tlearn: 1408.3860741\ttotal: 42.7s\tremaining: 2m 23s\n",
      "229:\tlearn: 1407.2305728\ttotal: 42.9s\tremaining: 2m 23s\n",
      "230:\tlearn: 1406.7791459\ttotal: 43.1s\tremaining: 2m 23s\n",
      "231:\tlearn: 1406.2031035\ttotal: 43.3s\tremaining: 2m 23s\n",
      "232:\tlearn: 1405.2248583\ttotal: 43.4s\tremaining: 2m 23s\n",
      "233:\tlearn: 1404.0826122\ttotal: 43.6s\tremaining: 2m 22s\n",
      "234:\tlearn: 1403.1404188\ttotal: 43.8s\tremaining: 2m 22s\n",
      "235:\tlearn: 1402.1360069\ttotal: 44s\tremaining: 2m 22s\n",
      "236:\tlearn: 1401.5660477\ttotal: 44.2s\tremaining: 2m 22s\n",
      "237:\tlearn: 1400.4613540\ttotal: 44.4s\tremaining: 2m 22s\n",
      "238:\tlearn: 1399.9509777\ttotal: 44.5s\tremaining: 2m 21s\n",
      "239:\tlearn: 1399.0712990\ttotal: 44.7s\tremaining: 2m 21s\n",
      "240:\tlearn: 1397.5683718\ttotal: 44.9s\tremaining: 2m 21s\n",
      "241:\tlearn: 1396.2213256\ttotal: 45.1s\tremaining: 2m 21s\n",
      "242:\tlearn: 1395.8699558\ttotal: 45.3s\tremaining: 2m 21s\n",
      "243:\tlearn: 1395.0903308\ttotal: 45.5s\tremaining: 2m 20s\n",
      "244:\tlearn: 1394.4425269\ttotal: 45.6s\tremaining: 2m 20s\n",
      "245:\tlearn: 1393.4687169\ttotal: 45.8s\tremaining: 2m 20s\n",
      "246:\tlearn: 1392.9675731\ttotal: 46s\tremaining: 2m 20s\n",
      "247:\tlearn: 1392.1652366\ttotal: 46.2s\tremaining: 2m 20s\n",
      "248:\tlearn: 1391.5900440\ttotal: 46.4s\tremaining: 2m 20s\n",
      "249:\tlearn: 1390.7943820\ttotal: 46.6s\tremaining: 2m 19s\n",
      "250:\tlearn: 1390.0435227\ttotal: 46.8s\tremaining: 2m 19s\n",
      "251:\tlearn: 1389.1000523\ttotal: 47s\tremaining: 2m 19s\n",
      "252:\tlearn: 1388.6939626\ttotal: 47.1s\tremaining: 2m 19s\n",
      "253:\tlearn: 1388.0967015\ttotal: 47.3s\tremaining: 2m 18s\n",
      "254:\tlearn: 1387.5993589\ttotal: 47.5s\tremaining: 2m 18s\n",
      "255:\tlearn: 1386.8388211\ttotal: 47.7s\tremaining: 2m 18s\n",
      "256:\tlearn: 1386.5335621\ttotal: 47.9s\tremaining: 2m 18s\n",
      "257:\tlearn: 1385.6860728\ttotal: 48.1s\tremaining: 2m 18s\n",
      "258:\tlearn: 1384.6561676\ttotal: 48.3s\tremaining: 2m 18s\n",
      "259:\tlearn: 1384.0130716\ttotal: 48.4s\tremaining: 2m 17s\n",
      "260:\tlearn: 1382.9578851\ttotal: 48.6s\tremaining: 2m 17s\n",
      "261:\tlearn: 1382.2813456\ttotal: 48.8s\tremaining: 2m 17s\n",
      "262:\tlearn: 1381.4210979\ttotal: 49s\tremaining: 2m 17s\n",
      "263:\tlearn: 1380.5335268\ttotal: 49.2s\tremaining: 2m 17s\n",
      "264:\tlearn: 1379.8139511\ttotal: 49.4s\tremaining: 2m 16s\n",
      "265:\tlearn: 1378.9886489\ttotal: 49.5s\tremaining: 2m 16s\n",
      "266:\tlearn: 1378.8018403\ttotal: 49.7s\tremaining: 2m 16s\n",
      "267:\tlearn: 1378.2136953\ttotal: 49.9s\tremaining: 2m 16s\n",
      "268:\tlearn: 1377.8057226\ttotal: 50.1s\tremaining: 2m 16s\n",
      "269:\tlearn: 1377.5974188\ttotal: 50.3s\tremaining: 2m 15s\n",
      "270:\tlearn: 1376.3884992\ttotal: 50.5s\tremaining: 2m 15s\n",
      "271:\tlearn: 1375.6006281\ttotal: 50.7s\tremaining: 2m 15s\n",
      "272:\tlearn: 1375.1565444\ttotal: 50.9s\tremaining: 2m 15s\n",
      "273:\tlearn: 1374.2234227\ttotal: 51s\tremaining: 2m 15s\n",
      "274:\tlearn: 1373.6507297\ttotal: 51.2s\tremaining: 2m 15s\n",
      "275:\tlearn: 1372.9627682\ttotal: 51.4s\tremaining: 2m 14s\n",
      "276:\tlearn: 1372.2716475\ttotal: 51.6s\tremaining: 2m 14s\n",
      "277:\tlearn: 1371.6772262\ttotal: 51.8s\tremaining: 2m 14s\n",
      "278:\tlearn: 1370.3583277\ttotal: 52s\tremaining: 2m 14s\n",
      "279:\tlearn: 1369.8080675\ttotal: 52.2s\tremaining: 2m 14s\n",
      "280:\tlearn: 1369.2982868\ttotal: 52.4s\tremaining: 2m 14s\n",
      "281:\tlearn: 1368.3261871\ttotal: 52.6s\tremaining: 2m 14s\n",
      "282:\tlearn: 1367.4350825\ttotal: 52.8s\tremaining: 2m 13s\n",
      "283:\tlearn: 1367.2388257\ttotal: 53s\tremaining: 2m 13s\n",
      "284:\tlearn: 1366.2256854\ttotal: 53.2s\tremaining: 2m 13s\n",
      "285:\tlearn: 1365.8288692\ttotal: 53.4s\tremaining: 2m 13s\n",
      "286:\tlearn: 1365.0379708\ttotal: 53.6s\tremaining: 2m 13s\n",
      "287:\tlearn: 1364.3349935\ttotal: 53.8s\tremaining: 2m 13s\n",
      "288:\tlearn: 1363.7735208\ttotal: 54s\tremaining: 2m 12s\n",
      "289:\tlearn: 1362.5162973\ttotal: 54.2s\tremaining: 2m 12s\n",
      "290:\tlearn: 1361.5563793\ttotal: 54.4s\tremaining: 2m 12s\n",
      "291:\tlearn: 1360.7282663\ttotal: 54.6s\tremaining: 2m 12s\n",
      "292:\tlearn: 1360.2923649\ttotal: 54.8s\tremaining: 2m 12s\n",
      "293:\tlearn: 1359.6199276\ttotal: 55s\tremaining: 2m 12s\n",
      "294:\tlearn: 1359.3769823\ttotal: 55.2s\tremaining: 2m 11s\n",
      "295:\tlearn: 1358.6668000\ttotal: 55.4s\tremaining: 2m 11s\n",
      "296:\tlearn: 1357.6362093\ttotal: 55.6s\tremaining: 2m 11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297:\tlearn: 1356.8652721\ttotal: 55.7s\tremaining: 2m 11s\n",
      "298:\tlearn: 1355.8969581\ttotal: 55.9s\tremaining: 2m 11s\n",
      "299:\tlearn: 1354.7817910\ttotal: 56.1s\tremaining: 2m 10s\n",
      "300:\tlearn: 1353.7691000\ttotal: 56.3s\tremaining: 2m 10s\n",
      "301:\tlearn: 1352.9682336\ttotal: 56.5s\tremaining: 2m 10s\n",
      "302:\tlearn: 1352.2934072\ttotal: 56.7s\tremaining: 2m 10s\n",
      "303:\tlearn: 1351.6090457\ttotal: 56.9s\tremaining: 2m 10s\n",
      "304:\tlearn: 1351.0755928\ttotal: 57.1s\tremaining: 2m 10s\n",
      "305:\tlearn: 1350.1650991\ttotal: 57.3s\tremaining: 2m 9s\n",
      "306:\tlearn: 1349.4587526\ttotal: 57.4s\tremaining: 2m 9s\n",
      "307:\tlearn: 1349.1570569\ttotal: 57.6s\tremaining: 2m 9s\n",
      "308:\tlearn: 1348.1521555\ttotal: 57.8s\tremaining: 2m 9s\n",
      "309:\tlearn: 1347.5087154\ttotal: 58s\tremaining: 2m 9s\n",
      "310:\tlearn: 1346.7978517\ttotal: 58.2s\tremaining: 2m 8s\n",
      "311:\tlearn: 1346.2037487\ttotal: 58.3s\tremaining: 2m 8s\n",
      "312:\tlearn: 1345.7312546\ttotal: 58.5s\tremaining: 2m 8s\n",
      "313:\tlearn: 1345.3714175\ttotal: 58.7s\tremaining: 2m 8s\n",
      "314:\tlearn: 1345.0265852\ttotal: 58.9s\tremaining: 2m 8s\n",
      "315:\tlearn: 1344.3369314\ttotal: 59.1s\tremaining: 2m 7s\n",
      "316:\tlearn: 1343.6325378\ttotal: 59.3s\tremaining: 2m 7s\n",
      "317:\tlearn: 1342.8221261\ttotal: 59.5s\tremaining: 2m 7s\n",
      "318:\tlearn: 1342.2464822\ttotal: 59.7s\tremaining: 2m 7s\n",
      "319:\tlearn: 1340.8692761\ttotal: 59.8s\tremaining: 2m 7s\n",
      "320:\tlearn: 1340.0111423\ttotal: 1m\tremaining: 2m 6s\n",
      "321:\tlearn: 1339.3419107\ttotal: 1m\tremaining: 2m 6s\n",
      "322:\tlearn: 1338.7469762\ttotal: 1m\tremaining: 2m 6s\n",
      "323:\tlearn: 1337.8606375\ttotal: 1m\tremaining: 2m 6s\n",
      "324:\tlearn: 1337.0641393\ttotal: 1m\tremaining: 2m 6s\n",
      "325:\tlearn: 1336.2995764\ttotal: 1m\tremaining: 2m 6s\n",
      "326:\tlearn: 1335.5551087\ttotal: 1m 1s\tremaining: 2m 5s\n",
      "327:\tlearn: 1335.0434017\ttotal: 1m 1s\tremaining: 2m 5s\n",
      "328:\tlearn: 1333.9937321\ttotal: 1m 1s\tremaining: 2m 5s\n",
      "329:\tlearn: 1333.2080120\ttotal: 1m 1s\tremaining: 2m 5s\n",
      "330:\tlearn: 1332.8830822\ttotal: 1m 1s\tremaining: 2m 5s\n",
      "331:\tlearn: 1332.4205848\ttotal: 1m 2s\tremaining: 2m 4s\n",
      "332:\tlearn: 1331.6781509\ttotal: 1m 2s\tremaining: 2m 4s\n",
      "333:\tlearn: 1331.4323742\ttotal: 1m 2s\tremaining: 2m 4s\n",
      "334:\tlearn: 1330.7929176\ttotal: 1m 2s\tremaining: 2m 4s\n",
      "335:\tlearn: 1330.3407861\ttotal: 1m 2s\tremaining: 2m 4s\n",
      "336:\tlearn: 1329.6796387\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "337:\tlearn: 1328.8982395\ttotal: 1m 3s\tremaining: 2m 4s\n",
      "338:\tlearn: 1328.2149221\ttotal: 1m 3s\tremaining: 2m 3s\n",
      "339:\tlearn: 1327.7463999\ttotal: 1m 3s\tremaining: 2m 3s\n",
      "340:\tlearn: 1326.9542733\ttotal: 1m 3s\tremaining: 2m 3s\n",
      "341:\tlearn: 1326.6107255\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "342:\tlearn: 1325.9860682\ttotal: 1m 4s\tremaining: 2m 3s\n",
      "343:\tlearn: 1325.5620186\ttotal: 1m 4s\tremaining: 2m 2s\n",
      "344:\tlearn: 1325.3355512\ttotal: 1m 4s\tremaining: 2m 2s\n",
      "345:\tlearn: 1324.6451535\ttotal: 1m 4s\tremaining: 2m 2s\n",
      "346:\tlearn: 1323.6946807\ttotal: 1m 4s\tremaining: 2m 2s\n",
      "347:\tlearn: 1322.9352704\ttotal: 1m 5s\tremaining: 2m 2s\n",
      "348:\tlearn: 1322.1900774\ttotal: 1m 5s\tremaining: 2m 1s\n",
      "349:\tlearn: 1321.6002425\ttotal: 1m 5s\tremaining: 2m 1s\n",
      "350:\tlearn: 1321.2926453\ttotal: 1m 5s\tremaining: 2m 1s\n",
      "351:\tlearn: 1320.6690749\ttotal: 1m 5s\tremaining: 2m 1s\n",
      "352:\tlearn: 1319.9979208\ttotal: 1m 6s\tremaining: 2m 1s\n",
      "353:\tlearn: 1319.5694857\ttotal: 1m 6s\tremaining: 2m\n",
      "354:\tlearn: 1318.8127765\ttotal: 1m 6s\tremaining: 2m\n",
      "355:\tlearn: 1318.1761846\ttotal: 1m 6s\tremaining: 2m\n",
      "356:\tlearn: 1317.5341203\ttotal: 1m 6s\tremaining: 2m\n",
      "357:\tlearn: 1316.7599953\ttotal: 1m 6s\tremaining: 2m\n",
      "358:\tlearn: 1316.0934322\ttotal: 1m 7s\tremaining: 1m 59s\n",
      "359:\tlearn: 1315.3906576\ttotal: 1m 7s\tremaining: 1m 59s\n",
      "360:\tlearn: 1315.1512105\ttotal: 1m 7s\tremaining: 1m 59s\n",
      "361:\tlearn: 1314.8140625\ttotal: 1m 7s\tremaining: 1m 59s\n",
      "362:\tlearn: 1314.2208137\ttotal: 1m 7s\tremaining: 1m 59s\n",
      "363:\tlearn: 1313.1340526\ttotal: 1m 8s\tremaining: 1m 59s\n",
      "364:\tlearn: 1312.8028481\ttotal: 1m 8s\tremaining: 1m 58s\n",
      "365:\tlearn: 1312.0769855\ttotal: 1m 8s\tremaining: 1m 58s\n",
      "366:\tlearn: 1311.0441614\ttotal: 1m 8s\tremaining: 1m 58s\n",
      "367:\tlearn: 1310.3445119\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "368:\tlearn: 1310.1362693\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "369:\tlearn: 1309.5232385\ttotal: 1m 9s\tremaining: 1m 58s\n",
      "370:\tlearn: 1308.7380984\ttotal: 1m 9s\tremaining: 1m 57s\n",
      "371:\tlearn: 1308.3363672\ttotal: 1m 9s\tremaining: 1m 57s\n",
      "372:\tlearn: 1307.9690401\ttotal: 1m 9s\tremaining: 1m 57s\n",
      "373:\tlearn: 1307.5489425\ttotal: 1m 10s\tremaining: 1m 57s\n",
      "374:\tlearn: 1307.0434421\ttotal: 1m 10s\tremaining: 1m 57s\n",
      "375:\tlearn: 1306.2133003\ttotal: 1m 10s\tremaining: 1m 56s\n",
      "376:\tlearn: 1305.8364972\ttotal: 1m 10s\tremaining: 1m 56s\n",
      "377:\tlearn: 1305.4437990\ttotal: 1m 10s\tremaining: 1m 56s\n",
      "378:\tlearn: 1305.1386043\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "379:\tlearn: 1304.6986336\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "380:\tlearn: 1304.3480252\ttotal: 1m 11s\tremaining: 1m 56s\n",
      "381:\tlearn: 1304.0115878\ttotal: 1m 11s\tremaining: 1m 55s\n",
      "382:\tlearn: 1303.3594217\ttotal: 1m 11s\tremaining: 1m 55s\n",
      "383:\tlearn: 1302.7297878\ttotal: 1m 11s\tremaining: 1m 55s\n",
      "384:\tlearn: 1302.2593869\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "385:\tlearn: 1301.6649646\ttotal: 1m 12s\tremaining: 1m 55s\n",
      "386:\tlearn: 1301.0710493\ttotal: 1m 12s\tremaining: 1m 54s\n",
      "387:\tlearn: 1300.2621361\ttotal: 1m 12s\tremaining: 1m 54s\n",
      "388:\tlearn: 1300.1597968\ttotal: 1m 12s\tremaining: 1m 54s\n",
      "389:\tlearn: 1299.7089343\ttotal: 1m 13s\tremaining: 1m 54s\n",
      "390:\tlearn: 1299.0613211\ttotal: 1m 13s\tremaining: 1m 53s\n",
      "391:\tlearn: 1298.8436602\ttotal: 1m 13s\tremaining: 1m 53s\n",
      "392:\tlearn: 1298.0092583\ttotal: 1m 13s\tremaining: 1m 53s\n",
      "393:\tlearn: 1297.2087346\ttotal: 1m 13s\tremaining: 1m 53s\n",
      "394:\tlearn: 1296.6821322\ttotal: 1m 13s\tremaining: 1m 53s\n",
      "395:\tlearn: 1296.1792080\ttotal: 1m 14s\tremaining: 1m 53s\n",
      "396:\tlearn: 1295.6532115\ttotal: 1m 14s\tremaining: 1m 52s\n",
      "397:\tlearn: 1294.9989941\ttotal: 1m 14s\tremaining: 1m 52s\n",
      "398:\tlearn: 1294.9003043\ttotal: 1m 14s\tremaining: 1m 52s\n",
      "399:\tlearn: 1294.3371636\ttotal: 1m 14s\tremaining: 1m 52s\n",
      "400:\tlearn: 1294.0889185\ttotal: 1m 15s\tremaining: 1m 52s\n",
      "401:\tlearn: 1293.6236559\ttotal: 1m 15s\tremaining: 1m 51s\n",
      "402:\tlearn: 1292.9522141\ttotal: 1m 15s\tremaining: 1m 51s\n",
      "403:\tlearn: 1292.6533224\ttotal: 1m 15s\tremaining: 1m 51s\n",
      "404:\tlearn: 1291.8893277\ttotal: 1m 15s\tremaining: 1m 51s\n",
      "405:\tlearn: 1291.1123501\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "406:\tlearn: 1290.8739684\ttotal: 1m 16s\tremaining: 1m 51s\n",
      "407:\tlearn: 1290.1949753\ttotal: 1m 16s\tremaining: 1m 50s\n",
      "408:\tlearn: 1289.8411345\ttotal: 1m 16s\tremaining: 1m 50s\n",
      "409:\tlearn: 1289.4020587\ttotal: 1m 16s\tremaining: 1m 50s\n",
      "410:\tlearn: 1288.9841209\ttotal: 1m 16s\tremaining: 1m 50s\n",
      "411:\tlearn: 1288.0416394\ttotal: 1m 17s\tremaining: 1m 50s\n",
      "412:\tlearn: 1287.5958196\ttotal: 1m 17s\tremaining: 1m 49s\n",
      "413:\tlearn: 1287.1626483\ttotal: 1m 17s\tremaining: 1m 49s\n",
      "414:\tlearn: 1286.8815896\ttotal: 1m 17s\tremaining: 1m 49s\n",
      "415:\tlearn: 1286.3711352\ttotal: 1m 17s\tremaining: 1m 49s\n",
      "416:\tlearn: 1286.1485939\ttotal: 1m 18s\tremaining: 1m 49s\n",
      "417:\tlearn: 1285.9541645\ttotal: 1m 18s\tremaining: 1m 48s\n",
      "418:\tlearn: 1285.6701189\ttotal: 1m 18s\tremaining: 1m 48s\n",
      "419:\tlearn: 1284.9402399\ttotal: 1m 18s\tremaining: 1m 48s\n",
      "420:\tlearn: 1284.7219831\ttotal: 1m 18s\tremaining: 1m 48s\n",
      "421:\tlearn: 1283.4584541\ttotal: 1m 18s\tremaining: 1m 48s\n",
      "422:\tlearn: 1282.7940305\ttotal: 1m 19s\tremaining: 1m 47s\n",
      "423:\tlearn: 1282.0690705\ttotal: 1m 19s\tremaining: 1m 47s\n",
      "424:\tlearn: 1281.9626969\ttotal: 1m 19s\tremaining: 1m 47s\n",
      "425:\tlearn: 1281.1589677\ttotal: 1m 19s\tremaining: 1m 47s\n",
      "426:\tlearn: 1280.3047494\ttotal: 1m 19s\tremaining: 1m 47s\n",
      "427:\tlearn: 1279.8873010\ttotal: 1m 19s\tremaining: 1m 46s\n",
      "428:\tlearn: 1279.3193887\ttotal: 1m 20s\tremaining: 1m 46s\n",
      "429:\tlearn: 1279.0425770\ttotal: 1m 20s\tremaining: 1m 46s\n",
      "430:\tlearn: 1278.8579036\ttotal: 1m 20s\tremaining: 1m 46s\n",
      "431:\tlearn: 1278.8287950\ttotal: 1m 20s\tremaining: 1m 46s\n",
      "432:\tlearn: 1278.0839801\ttotal: 1m 20s\tremaining: 1m 45s\n",
      "433:\tlearn: 1277.8254622\ttotal: 1m 21s\tremaining: 1m 45s\n",
      "434:\tlearn: 1277.3135180\ttotal: 1m 21s\tremaining: 1m 45s\n",
      "435:\tlearn: 1276.5113831\ttotal: 1m 21s\tremaining: 1m 45s\n",
      "436:\tlearn: 1276.1741766\ttotal: 1m 21s\tremaining: 1m 45s\n",
      "437:\tlearn: 1275.6978863\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "438:\tlearn: 1274.9992712\ttotal: 1m 21s\tremaining: 1m 44s\n",
      "439:\tlearn: 1274.5744641\ttotal: 1m 22s\tremaining: 1m 44s\n",
      "440:\tlearn: 1273.4536041\ttotal: 1m 22s\tremaining: 1m 44s\n",
      "441:\tlearn: 1273.1101204\ttotal: 1m 22s\tremaining: 1m 44s\n",
      "442:\tlearn: 1272.7938905\ttotal: 1m 22s\tremaining: 1m 43s\n",
      "443:\tlearn: 1271.9390375\ttotal: 1m 22s\tremaining: 1m 43s\n",
      "444:\tlearn: 1271.3570868\ttotal: 1m 23s\tremaining: 1m 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445:\tlearn: 1270.9503530\ttotal: 1m 23s\tremaining: 1m 43s\n",
      "446:\tlearn: 1270.1825921\ttotal: 1m 23s\tremaining: 1m 43s\n",
      "447:\tlearn: 1269.7703540\ttotal: 1m 23s\tremaining: 1m 43s\n",
      "448:\tlearn: 1269.1705382\ttotal: 1m 23s\tremaining: 1m 42s\n",
      "449:\tlearn: 1268.5622071\ttotal: 1m 23s\tremaining: 1m 42s\n",
      "450:\tlearn: 1268.3264603\ttotal: 1m 24s\tremaining: 1m 42s\n",
      "451:\tlearn: 1267.9221806\ttotal: 1m 24s\tremaining: 1m 42s\n",
      "452:\tlearn: 1267.3979266\ttotal: 1m 24s\tremaining: 1m 42s\n",
      "453:\tlearn: 1266.9456742\ttotal: 1m 24s\tremaining: 1m 41s\n",
      "454:\tlearn: 1266.6184603\ttotal: 1m 24s\tremaining: 1m 41s\n",
      "455:\tlearn: 1266.0055508\ttotal: 1m 25s\tremaining: 1m 41s\n",
      "456:\tlearn: 1265.6851204\ttotal: 1m 25s\tremaining: 1m 41s\n",
      "457:\tlearn: 1265.1105143\ttotal: 1m 25s\tremaining: 1m 41s\n",
      "458:\tlearn: 1264.5705506\ttotal: 1m 25s\tremaining: 1m 40s\n",
      "459:\tlearn: 1264.2098367\ttotal: 1m 25s\tremaining: 1m 40s\n",
      "460:\tlearn: 1263.7644569\ttotal: 1m 25s\tremaining: 1m 40s\n",
      "461:\tlearn: 1262.8594988\ttotal: 1m 26s\tremaining: 1m 40s\n",
      "462:\tlearn: 1262.0445947\ttotal: 1m 26s\tremaining: 1m 40s\n",
      "463:\tlearn: 1261.4894420\ttotal: 1m 26s\tremaining: 1m 39s\n",
      "464:\tlearn: 1260.7496103\ttotal: 1m 26s\tremaining: 1m 39s\n",
      "465:\tlearn: 1260.6645836\ttotal: 1m 26s\tremaining: 1m 39s\n",
      "466:\tlearn: 1259.8202164\ttotal: 1m 26s\tremaining: 1m 39s\n",
      "467:\tlearn: 1259.2552917\ttotal: 1m 27s\tremaining: 1m 39s\n",
      "468:\tlearn: 1258.8032658\ttotal: 1m 27s\tremaining: 1m 38s\n",
      "469:\tlearn: 1258.1726436\ttotal: 1m 27s\tremaining: 1m 38s\n",
      "470:\tlearn: 1257.3242338\ttotal: 1m 27s\tremaining: 1m 38s\n",
      "471:\tlearn: 1256.9442874\ttotal: 1m 27s\tremaining: 1m 38s\n",
      "472:\tlearn: 1256.8375050\ttotal: 1m 28s\tremaining: 1m 38s\n",
      "473:\tlearn: 1256.4893901\ttotal: 1m 28s\tremaining: 1m 37s\n",
      "474:\tlearn: 1256.3313565\ttotal: 1m 28s\tremaining: 1m 37s\n",
      "475:\tlearn: 1255.8762389\ttotal: 1m 28s\tremaining: 1m 37s\n",
      "476:\tlearn: 1255.6539465\ttotal: 1m 28s\tremaining: 1m 37s\n",
      "477:\tlearn: 1255.5303025\ttotal: 1m 29s\tremaining: 1m 37s\n",
      "478:\tlearn: 1254.9767695\ttotal: 1m 29s\tremaining: 1m 37s\n",
      "479:\tlearn: 1254.7654323\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "480:\tlearn: 1253.9418188\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "481:\tlearn: 1253.5409468\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "482:\tlearn: 1253.0256753\ttotal: 1m 29s\tremaining: 1m 36s\n",
      "483:\tlearn: 1252.5044379\ttotal: 1m 30s\tremaining: 1m 36s\n",
      "484:\tlearn: 1252.1508121\ttotal: 1m 30s\tremaining: 1m 35s\n",
      "485:\tlearn: 1251.7722593\ttotal: 1m 30s\tremaining: 1m 35s\n",
      "486:\tlearn: 1251.0128007\ttotal: 1m 30s\tremaining: 1m 35s\n",
      "487:\tlearn: 1250.4812527\ttotal: 1m 30s\tremaining: 1m 35s\n",
      "488:\tlearn: 1249.5750159\ttotal: 1m 31s\tremaining: 1m 35s\n",
      "489:\tlearn: 1249.0755234\ttotal: 1m 31s\tremaining: 1m 35s\n",
      "490:\tlearn: 1248.8680515\ttotal: 1m 31s\tremaining: 1m 34s\n",
      "491:\tlearn: 1248.4878525\ttotal: 1m 31s\tremaining: 1m 34s\n",
      "492:\tlearn: 1247.1785001\ttotal: 1m 31s\tremaining: 1m 34s\n",
      "493:\tlearn: 1246.8810895\ttotal: 1m 32s\tremaining: 1m 34s\n",
      "494:\tlearn: 1246.6433329\ttotal: 1m 32s\tremaining: 1m 34s\n",
      "495:\tlearn: 1246.1320631\ttotal: 1m 32s\tremaining: 1m 34s\n",
      "496:\tlearn: 1246.0982672\ttotal: 1m 32s\tremaining: 1m 33s\n",
      "497:\tlearn: 1245.7929213\ttotal: 1m 32s\tremaining: 1m 33s\n",
      "498:\tlearn: 1245.4335416\ttotal: 1m 33s\tremaining: 1m 33s\n",
      "499:\tlearn: 1245.1472531\ttotal: 1m 33s\tremaining: 1m 33s\n",
      "500:\tlearn: 1244.7278725\ttotal: 1m 33s\tremaining: 1m 33s\n",
      "501:\tlearn: 1244.4634176\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "502:\tlearn: 1244.1232828\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "503:\tlearn: 1243.6367603\ttotal: 1m 33s\tremaining: 1m 32s\n",
      "504:\tlearn: 1243.0678865\ttotal: 1m 34s\tremaining: 1m 32s\n",
      "505:\tlearn: 1242.5927544\ttotal: 1m 34s\tremaining: 1m 32s\n",
      "506:\tlearn: 1242.1330046\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "507:\tlearn: 1241.9610767\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "508:\tlearn: 1241.6505802\ttotal: 1m 34s\tremaining: 1m 31s\n",
      "509:\tlearn: 1241.1684856\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "510:\tlearn: 1240.5867667\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "511:\tlearn: 1240.1755469\ttotal: 1m 35s\tremaining: 1m 31s\n",
      "512:\tlearn: 1240.0187611\ttotal: 1m 35s\tremaining: 1m 30s\n",
      "513:\tlearn: 1239.5129019\ttotal: 1m 35s\tremaining: 1m 30s\n",
      "514:\tlearn: 1239.3254821\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "515:\tlearn: 1238.5484136\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "516:\tlearn: 1238.3006446\ttotal: 1m 36s\tremaining: 1m 30s\n",
      "517:\tlearn: 1238.0730851\ttotal: 1m 36s\tremaining: 1m 29s\n",
      "518:\tlearn: 1237.7338990\ttotal: 1m 36s\tremaining: 1m 29s\n",
      "519:\tlearn: 1237.4209490\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "520:\tlearn: 1237.1369951\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "521:\tlearn: 1236.7401522\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "522:\tlearn: 1236.5265806\ttotal: 1m 37s\tremaining: 1m 29s\n",
      "523:\tlearn: 1236.3240140\ttotal: 1m 37s\tremaining: 1m 28s\n",
      "524:\tlearn: 1235.6374063\ttotal: 1m 37s\tremaining: 1m 28s\n",
      "525:\tlearn: 1234.8738901\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "526:\tlearn: 1234.5184255\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "527:\tlearn: 1234.1451509\ttotal: 1m 38s\tremaining: 1m 28s\n",
      "528:\tlearn: 1233.7164190\ttotal: 1m 38s\tremaining: 1m 27s\n",
      "529:\tlearn: 1233.3303978\ttotal: 1m 38s\tremaining: 1m 27s\n",
      "530:\tlearn: 1233.0907043\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "531:\tlearn: 1232.8115236\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "532:\tlearn: 1232.3682509\ttotal: 1m 39s\tremaining: 1m 27s\n",
      "533:\tlearn: 1231.8214592\ttotal: 1m 39s\tremaining: 1m 26s\n",
      "534:\tlearn: 1231.3016327\ttotal: 1m 39s\tremaining: 1m 26s\n",
      "535:\tlearn: 1230.9423249\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "536:\tlearn: 1230.6036658\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "537:\tlearn: 1229.8238204\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "538:\tlearn: 1229.3110971\ttotal: 1m 40s\tremaining: 1m 26s\n",
      "539:\tlearn: 1229.0416029\ttotal: 1m 40s\tremaining: 1m 25s\n",
      "540:\tlearn: 1228.8462281\ttotal: 1m 40s\tremaining: 1m 25s\n",
      "541:\tlearn: 1228.4974586\ttotal: 1m 41s\tremaining: 1m 25s\n",
      "542:\tlearn: 1228.1417271\ttotal: 1m 41s\tremaining: 1m 25s\n",
      "543:\tlearn: 1227.6266969\ttotal: 1m 41s\tremaining: 1m 25s\n",
      "544:\tlearn: 1227.1588466\ttotal: 1m 41s\tremaining: 1m 24s\n",
      "545:\tlearn: 1226.7828212\ttotal: 1m 41s\tremaining: 1m 24s\n",
      "546:\tlearn: 1226.0771049\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "547:\tlearn: 1225.5569642\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "548:\tlearn: 1224.8459996\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "549:\tlearn: 1224.4304308\ttotal: 1m 42s\tremaining: 1m 24s\n",
      "550:\tlearn: 1224.0995027\ttotal: 1m 42s\tremaining: 1m 23s\n",
      "551:\tlearn: 1223.7063460\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "552:\tlearn: 1222.8274319\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "553:\tlearn: 1222.2652765\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "554:\tlearn: 1221.9050568\ttotal: 1m 43s\tremaining: 1m 23s\n",
      "555:\tlearn: 1221.5197430\ttotal: 1m 44s\tremaining: 1m 23s\n",
      "556:\tlearn: 1221.3309407\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "557:\tlearn: 1220.9921640\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "558:\tlearn: 1220.9229434\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "559:\tlearn: 1220.4752507\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "560:\tlearn: 1220.3061416\ttotal: 1m 44s\tremaining: 1m 22s\n",
      "561:\tlearn: 1219.6812480\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "562:\tlearn: 1219.1768610\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "563:\tlearn: 1218.7888624\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "564:\tlearn: 1218.5229200\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "565:\tlearn: 1218.2800880\ttotal: 1m 45s\tremaining: 1m 21s\n",
      "566:\tlearn: 1217.8481413\ttotal: 1m 46s\tremaining: 1m 21s\n",
      "567:\tlearn: 1217.4071481\ttotal: 1m 46s\tremaining: 1m 20s\n",
      "568:\tlearn: 1217.1841872\ttotal: 1m 46s\tremaining: 1m 20s\n",
      "569:\tlearn: 1216.6504949\ttotal: 1m 46s\tremaining: 1m 20s\n",
      "570:\tlearn: 1216.1534342\ttotal: 1m 46s\tremaining: 1m 20s\n",
      "571:\tlearn: 1215.8676810\ttotal: 1m 47s\tremaining: 1m 20s\n",
      "572:\tlearn: 1215.4623330\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "573:\tlearn: 1215.0608079\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "574:\tlearn: 1214.7616309\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "575:\tlearn: 1214.4744264\ttotal: 1m 47s\tremaining: 1m 19s\n",
      "576:\tlearn: 1213.9597451\ttotal: 1m 48s\tremaining: 1m 19s\n",
      "577:\tlearn: 1213.5229125\ttotal: 1m 48s\tremaining: 1m 19s\n",
      "578:\tlearn: 1213.0680297\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "579:\tlearn: 1212.2788284\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "580:\tlearn: 1211.8935045\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "581:\tlearn: 1211.7042460\ttotal: 1m 48s\tremaining: 1m 18s\n",
      "582:\tlearn: 1211.2705932\ttotal: 1m 49s\tremaining: 1m 18s\n",
      "583:\tlearn: 1210.3637157\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "584:\tlearn: 1209.7120528\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "585:\tlearn: 1209.2815844\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "586:\tlearn: 1208.8247185\ttotal: 1m 49s\tremaining: 1m 17s\n",
      "587:\tlearn: 1208.5687247\ttotal: 1m 50s\tremaining: 1m 17s\n",
      "588:\tlearn: 1208.2699088\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "589:\tlearn: 1207.9323995\ttotal: 1m 50s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590:\tlearn: 1207.8851623\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "591:\tlearn: 1207.7629342\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "592:\tlearn: 1207.6238322\ttotal: 1m 50s\tremaining: 1m 16s\n",
      "593:\tlearn: 1207.1378965\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "594:\tlearn: 1206.9198224\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "595:\tlearn: 1206.1269671\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "596:\tlearn: 1205.9237433\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "597:\tlearn: 1205.4140903\ttotal: 1m 51s\tremaining: 1m 15s\n",
      "598:\tlearn: 1204.8652636\ttotal: 1m 52s\tremaining: 1m 15s\n",
      "599:\tlearn: 1204.4510693\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "600:\tlearn: 1204.0186996\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "601:\tlearn: 1203.4095839\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "602:\tlearn: 1203.0168443\ttotal: 1m 52s\tremaining: 1m 14s\n",
      "603:\tlearn: 1202.6689670\ttotal: 1m 53s\tremaining: 1m 14s\n",
      "604:\tlearn: 1202.3269040\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "605:\tlearn: 1201.7792323\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "606:\tlearn: 1201.3860565\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "607:\tlearn: 1200.8898321\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "608:\tlearn: 1200.2103627\ttotal: 1m 53s\tremaining: 1m 13s\n",
      "609:\tlearn: 1199.8652094\ttotal: 1m 54s\tremaining: 1m 13s\n",
      "610:\tlearn: 1199.5125894\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "611:\tlearn: 1199.1631363\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "612:\tlearn: 1199.0538310\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "613:\tlearn: 1198.8668117\ttotal: 1m 54s\tremaining: 1m 12s\n",
      "614:\tlearn: 1198.7710074\ttotal: 1m 55s\tremaining: 1m 12s\n",
      "615:\tlearn: 1198.4482086\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "616:\tlearn: 1198.2571426\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "617:\tlearn: 1198.0188421\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "618:\tlearn: 1197.6092749\ttotal: 1m 55s\tremaining: 1m 11s\n",
      "619:\tlearn: 1197.3726978\ttotal: 1m 56s\tremaining: 1m 11s\n",
      "620:\tlearn: 1196.8781648\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "621:\tlearn: 1196.6699107\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "622:\tlearn: 1196.0813607\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "623:\tlearn: 1195.8210495\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "624:\tlearn: 1195.6058074\ttotal: 1m 56s\tremaining: 1m 10s\n",
      "625:\tlearn: 1195.1779587\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "626:\tlearn: 1194.8991611\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "627:\tlearn: 1194.5373592\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "628:\tlearn: 1194.2693239\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "629:\tlearn: 1194.0322217\ttotal: 1m 57s\tremaining: 1m 9s\n",
      "630:\tlearn: 1193.7077624\ttotal: 1m 58s\tremaining: 1m 9s\n",
      "631:\tlearn: 1193.5595011\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "632:\tlearn: 1193.4466834\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "633:\tlearn: 1193.0866026\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "634:\tlearn: 1192.6775457\ttotal: 1m 58s\tremaining: 1m 8s\n",
      "635:\tlearn: 1192.0547905\ttotal: 1m 59s\tremaining: 1m 8s\n",
      "636:\tlearn: 1191.4326905\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "637:\tlearn: 1190.9242855\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "638:\tlearn: 1190.7186414\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "639:\tlearn: 1190.3064616\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "640:\tlearn: 1189.7273353\ttotal: 1m 59s\tremaining: 1m 7s\n",
      "641:\tlearn: 1189.3746586\ttotal: 2m\tremaining: 1m 7s\n",
      "642:\tlearn: 1188.7856277\ttotal: 2m\tremaining: 1m 6s\n",
      "643:\tlearn: 1188.5448224\ttotal: 2m\tremaining: 1m 6s\n",
      "644:\tlearn: 1187.9322149\ttotal: 2m\tremaining: 1m 6s\n",
      "645:\tlearn: 1187.5639576\ttotal: 2m\tremaining: 1m 6s\n",
      "646:\tlearn: 1187.1674602\ttotal: 2m 1s\tremaining: 1m 6s\n",
      "647:\tlearn: 1186.6514489\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "648:\tlearn: 1186.2962485\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "649:\tlearn: 1185.8192280\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "650:\tlearn: 1185.5485921\ttotal: 2m 1s\tremaining: 1m 5s\n",
      "651:\tlearn: 1185.0270415\ttotal: 2m 2s\tremaining: 1m 5s\n",
      "652:\tlearn: 1184.4251473\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "653:\tlearn: 1183.9793694\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "654:\tlearn: 1183.6472879\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "655:\tlearn: 1183.2468872\ttotal: 2m 2s\tremaining: 1m 4s\n",
      "656:\tlearn: 1182.8155523\ttotal: 2m 3s\tremaining: 1m 4s\n",
      "657:\tlearn: 1182.5262738\ttotal: 2m 3s\tremaining: 1m 4s\n",
      "658:\tlearn: 1182.1301355\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "659:\tlearn: 1181.8766872\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "660:\tlearn: 1181.4391874\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "661:\tlearn: 1180.8712649\ttotal: 2m 3s\tremaining: 1m 3s\n",
      "662:\tlearn: 1180.5792535\ttotal: 2m 4s\tremaining: 1m 3s\n",
      "663:\tlearn: 1180.3496339\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "664:\tlearn: 1180.0726490\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "665:\tlearn: 1179.8803816\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "666:\tlearn: 1179.3573354\ttotal: 2m 4s\tremaining: 1m 2s\n",
      "667:\tlearn: 1179.0345923\ttotal: 2m 5s\tremaining: 1m 2s\n",
      "668:\tlearn: 1178.8447354\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "669:\tlearn: 1178.7164094\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "670:\tlearn: 1178.3486096\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "671:\tlearn: 1178.0839272\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "672:\tlearn: 1177.9125879\ttotal: 2m 5s\tremaining: 1m 1s\n",
      "673:\tlearn: 1177.5250900\ttotal: 2m 6s\tremaining: 1m 1s\n",
      "674:\tlearn: 1177.3604577\ttotal: 2m 6s\tremaining: 1m\n",
      "675:\tlearn: 1177.1425298\ttotal: 2m 6s\tremaining: 1m\n",
      "676:\tlearn: 1176.6177059\ttotal: 2m 6s\tremaining: 1m\n",
      "677:\tlearn: 1176.2791123\ttotal: 2m 6s\tremaining: 1m\n",
      "678:\tlearn: 1175.6953156\ttotal: 2m 7s\tremaining: 1m\n",
      "679:\tlearn: 1175.2674654\ttotal: 2m 7s\tremaining: 59.9s\n",
      "680:\tlearn: 1174.9856189\ttotal: 2m 7s\tremaining: 59.7s\n",
      "681:\tlearn: 1174.8005568\ttotal: 2m 7s\tremaining: 59.5s\n",
      "682:\tlearn: 1174.3227276\ttotal: 2m 7s\tremaining: 59.3s\n",
      "683:\tlearn: 1174.1282748\ttotal: 2m 8s\tremaining: 59.1s\n",
      "684:\tlearn: 1173.5666440\ttotal: 2m 8s\tremaining: 59s\n",
      "685:\tlearn: 1173.3257167\ttotal: 2m 8s\tremaining: 58.8s\n",
      "686:\tlearn: 1172.9299295\ttotal: 2m 8s\tremaining: 58.6s\n",
      "687:\tlearn: 1172.5361419\ttotal: 2m 8s\tremaining: 58.4s\n",
      "688:\tlearn: 1172.2606282\ttotal: 2m 8s\tremaining: 58.2s\n",
      "689:\tlearn: 1172.1355963\ttotal: 2m 9s\tremaining: 58s\n",
      "690:\tlearn: 1171.8090235\ttotal: 2m 9s\tremaining: 57.8s\n",
      "691:\tlearn: 1171.4157772\ttotal: 2m 9s\tremaining: 57.6s\n",
      "692:\tlearn: 1171.3045088\ttotal: 2m 9s\tremaining: 57.4s\n",
      "693:\tlearn: 1171.1328777\ttotal: 2m 9s\tremaining: 57.2s\n",
      "694:\tlearn: 1170.9361502\ttotal: 2m 10s\tremaining: 57.1s\n",
      "695:\tlearn: 1170.6000654\ttotal: 2m 10s\tremaining: 56.9s\n",
      "696:\tlearn: 1170.2218334\ttotal: 2m 10s\tremaining: 56.7s\n",
      "697:\tlearn: 1170.0647455\ttotal: 2m 10s\tremaining: 56.5s\n",
      "698:\tlearn: 1169.4716980\ttotal: 2m 10s\tremaining: 56.3s\n",
      "699:\tlearn: 1169.0177057\ttotal: 2m 10s\tremaining: 56.1s\n",
      "700:\tlearn: 1168.4063292\ttotal: 2m 11s\tremaining: 55.9s\n",
      "701:\tlearn: 1167.9968046\ttotal: 2m 11s\tremaining: 55.8s\n",
      "702:\tlearn: 1167.6675838\ttotal: 2m 11s\tremaining: 55.6s\n",
      "703:\tlearn: 1167.0463250\ttotal: 2m 11s\tremaining: 55.4s\n",
      "704:\tlearn: 1166.8196478\ttotal: 2m 11s\tremaining: 55.2s\n",
      "705:\tlearn: 1166.5359484\ttotal: 2m 12s\tremaining: 55s\n",
      "706:\tlearn: 1166.0848534\ttotal: 2m 12s\tremaining: 54.8s\n",
      "707:\tlearn: 1165.7191638\ttotal: 2m 12s\tremaining: 54.6s\n",
      "708:\tlearn: 1165.1205232\ttotal: 2m 12s\tremaining: 54.5s\n",
      "709:\tlearn: 1164.8075126\ttotal: 2m 12s\tremaining: 54.3s\n",
      "710:\tlearn: 1164.3889951\ttotal: 2m 13s\tremaining: 54.1s\n",
      "711:\tlearn: 1164.1589557\ttotal: 2m 13s\tremaining: 53.9s\n",
      "712:\tlearn: 1163.8955386\ttotal: 2m 13s\tremaining: 53.7s\n",
      "713:\tlearn: 1163.5077787\ttotal: 2m 13s\tremaining: 53.5s\n",
      "714:\tlearn: 1163.1109778\ttotal: 2m 13s\tremaining: 53.3s\n",
      "715:\tlearn: 1162.8978598\ttotal: 2m 13s\tremaining: 53.1s\n",
      "716:\tlearn: 1162.3854514\ttotal: 2m 14s\tremaining: 52.9s\n",
      "717:\tlearn: 1162.1142318\ttotal: 2m 14s\tremaining: 52.8s\n",
      "718:\tlearn: 1161.4145884\ttotal: 2m 14s\tremaining: 52.6s\n",
      "719:\tlearn: 1160.9070065\ttotal: 2m 14s\tremaining: 52.4s\n",
      "720:\tlearn: 1160.7139887\ttotal: 2m 14s\tremaining: 52.2s\n",
      "721:\tlearn: 1160.4969092\ttotal: 2m 15s\tremaining: 52s\n",
      "722:\tlearn: 1159.8525903\ttotal: 2m 15s\tremaining: 51.8s\n",
      "723:\tlearn: 1159.6424330\ttotal: 2m 15s\tremaining: 51.6s\n",
      "724:\tlearn: 1159.5405374\ttotal: 2m 15s\tremaining: 51.4s\n",
      "725:\tlearn: 1159.3133687\ttotal: 2m 15s\tremaining: 51.2s\n",
      "726:\tlearn: 1158.9652978\ttotal: 2m 15s\tremaining: 51.1s\n",
      "727:\tlearn: 1158.7064526\ttotal: 2m 16s\tremaining: 50.9s\n",
      "728:\tlearn: 1158.5335354\ttotal: 2m 16s\tremaining: 50.7s\n",
      "729:\tlearn: 1158.1721358\ttotal: 2m 16s\tremaining: 50.5s\n",
      "730:\tlearn: 1158.0793024\ttotal: 2m 16s\tremaining: 50.3s\n",
      "731:\tlearn: 1157.7385996\ttotal: 2m 16s\tremaining: 50.1s\n",
      "732:\tlearn: 1157.5028187\ttotal: 2m 17s\tremaining: 49.9s\n",
      "733:\tlearn: 1157.3863307\ttotal: 2m 17s\tremaining: 49.8s\n",
      "734:\tlearn: 1157.0879641\ttotal: 2m 17s\tremaining: 49.6s\n",
      "735:\tlearn: 1156.8336679\ttotal: 2m 17s\tremaining: 49.4s\n",
      "736:\tlearn: 1156.6454176\ttotal: 2m 17s\tremaining: 49.2s\n",
      "737:\tlearn: 1156.4182878\ttotal: 2m 18s\tremaining: 49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738:\tlearn: 1156.1195923\ttotal: 2m 18s\tremaining: 48.8s\n",
      "739:\tlearn: 1155.6772252\ttotal: 2m 18s\tremaining: 48.6s\n",
      "740:\tlearn: 1155.2670602\ttotal: 2m 18s\tremaining: 48.4s\n",
      "741:\tlearn: 1155.2301328\ttotal: 2m 18s\tremaining: 48.2s\n",
      "742:\tlearn: 1154.8281853\ttotal: 2m 18s\tremaining: 48s\n",
      "743:\tlearn: 1154.3704611\ttotal: 2m 19s\tremaining: 47.8s\n",
      "744:\tlearn: 1154.0632569\ttotal: 2m 19s\tremaining: 47.6s\n",
      "745:\tlearn: 1154.0229346\ttotal: 2m 19s\tremaining: 47.5s\n",
      "746:\tlearn: 1153.6902417\ttotal: 2m 19s\tremaining: 47.3s\n",
      "747:\tlearn: 1153.2902543\ttotal: 2m 19s\tremaining: 47.1s\n",
      "748:\tlearn: 1153.0578264\ttotal: 2m 19s\tremaining: 46.9s\n",
      "749:\tlearn: 1152.7399382\ttotal: 2m 20s\tremaining: 46.7s\n",
      "750:\tlearn: 1152.0697792\ttotal: 2m 20s\tremaining: 46.5s\n",
      "751:\tlearn: 1151.5721311\ttotal: 2m 20s\tremaining: 46.3s\n",
      "752:\tlearn: 1151.4848256\ttotal: 2m 20s\tremaining: 46.1s\n",
      "753:\tlearn: 1151.1306834\ttotal: 2m 20s\tremaining: 46s\n",
      "754:\tlearn: 1150.9046822\ttotal: 2m 21s\tremaining: 45.8s\n",
      "755:\tlearn: 1150.5969741\ttotal: 2m 21s\tremaining: 45.6s\n",
      "756:\tlearn: 1150.5053481\ttotal: 2m 21s\tremaining: 45.4s\n",
      "757:\tlearn: 1149.9728305\ttotal: 2m 21s\tremaining: 45.2s\n",
      "758:\tlearn: 1149.4705812\ttotal: 2m 21s\tremaining: 45s\n",
      "759:\tlearn: 1148.9808648\ttotal: 2m 21s\tremaining: 44.8s\n",
      "760:\tlearn: 1148.5317303\ttotal: 2m 22s\tremaining: 44.6s\n",
      "761:\tlearn: 1148.2725972\ttotal: 2m 22s\tremaining: 44.4s\n",
      "762:\tlearn: 1148.2008057\ttotal: 2m 22s\tremaining: 44.3s\n",
      "763:\tlearn: 1147.6750281\ttotal: 2m 22s\tremaining: 44.1s\n",
      "764:\tlearn: 1147.3029227\ttotal: 2m 22s\tremaining: 43.9s\n",
      "765:\tlearn: 1146.8564090\ttotal: 2m 23s\tremaining: 43.7s\n",
      "766:\tlearn: 1146.7791262\ttotal: 2m 23s\tremaining: 43.5s\n",
      "767:\tlearn: 1146.3410982\ttotal: 2m 23s\tremaining: 43.3s\n",
      "768:\tlearn: 1146.1308875\ttotal: 2m 23s\tremaining: 43.1s\n",
      "769:\tlearn: 1145.8167079\ttotal: 2m 23s\tremaining: 42.9s\n",
      "770:\tlearn: 1145.5945536\ttotal: 2m 23s\tremaining: 42.8s\n",
      "771:\tlearn: 1145.2076804\ttotal: 2m 24s\tremaining: 42.6s\n",
      "772:\tlearn: 1144.9433016\ttotal: 2m 24s\tremaining: 42.4s\n",
      "773:\tlearn: 1144.6386234\ttotal: 2m 24s\tremaining: 42.2s\n",
      "774:\tlearn: 1144.3963823\ttotal: 2m 24s\tremaining: 42s\n",
      "775:\tlearn: 1144.0657626\ttotal: 2m 24s\tremaining: 41.8s\n",
      "776:\tlearn: 1143.9311641\ttotal: 2m 25s\tremaining: 41.6s\n",
      "777:\tlearn: 1143.2311972\ttotal: 2m 25s\tremaining: 41.5s\n",
      "778:\tlearn: 1142.8901959\ttotal: 2m 25s\tremaining: 41.3s\n",
      "779:\tlearn: 1142.5318363\ttotal: 2m 25s\tremaining: 41.1s\n",
      "780:\tlearn: 1142.2454181\ttotal: 2m 25s\tremaining: 40.9s\n",
      "781:\tlearn: 1141.9654272\ttotal: 2m 26s\tremaining: 40.7s\n",
      "782:\tlearn: 1141.5593796\ttotal: 2m 26s\tremaining: 40.5s\n",
      "783:\tlearn: 1140.7153937\ttotal: 2m 26s\tremaining: 40.3s\n",
      "784:\tlearn: 1140.2217923\ttotal: 2m 26s\tremaining: 40.1s\n",
      "785:\tlearn: 1140.0454735\ttotal: 2m 26s\tremaining: 40s\n",
      "786:\tlearn: 1139.8666694\ttotal: 2m 26s\tremaining: 39.8s\n",
      "787:\tlearn: 1139.2834554\ttotal: 2m 27s\tremaining: 39.6s\n",
      "788:\tlearn: 1139.0103951\ttotal: 2m 27s\tremaining: 39.4s\n",
      "789:\tlearn: 1138.7726752\ttotal: 2m 27s\tremaining: 39.2s\n",
      "790:\tlearn: 1138.6266403\ttotal: 2m 27s\tremaining: 39s\n",
      "791:\tlearn: 1138.1981622\ttotal: 2m 27s\tremaining: 38.8s\n",
      "792:\tlearn: 1137.9388674\ttotal: 2m 28s\tremaining: 38.6s\n",
      "793:\tlearn: 1137.4770208\ttotal: 2m 28s\tremaining: 38.5s\n",
      "794:\tlearn: 1137.1550656\ttotal: 2m 28s\tremaining: 38.3s\n",
      "795:\tlearn: 1136.7614965\ttotal: 2m 28s\tremaining: 38.1s\n",
      "796:\tlearn: 1136.2899358\ttotal: 2m 28s\tremaining: 37.9s\n",
      "797:\tlearn: 1136.0945815\ttotal: 2m 28s\tremaining: 37.7s\n",
      "798:\tlearn: 1135.6545840\ttotal: 2m 29s\tremaining: 37.5s\n",
      "799:\tlearn: 1135.3594542\ttotal: 2m 29s\tremaining: 37.3s\n",
      "800:\tlearn: 1135.1247273\ttotal: 2m 29s\tremaining: 37.1s\n",
      "801:\tlearn: 1135.0727774\ttotal: 2m 29s\tremaining: 37s\n",
      "802:\tlearn: 1134.7894368\ttotal: 2m 29s\tremaining: 36.8s\n",
      "803:\tlearn: 1134.3669080\ttotal: 2m 30s\tremaining: 36.6s\n",
      "804:\tlearn: 1134.1456552\ttotal: 2m 30s\tremaining: 36.4s\n",
      "805:\tlearn: 1133.6626584\ttotal: 2m 30s\tremaining: 36.2s\n",
      "806:\tlearn: 1133.4349922\ttotal: 2m 30s\tremaining: 36s\n",
      "807:\tlearn: 1132.7084744\ttotal: 2m 30s\tremaining: 35.8s\n",
      "808:\tlearn: 1132.5205006\ttotal: 2m 31s\tremaining: 35.7s\n",
      "809:\tlearn: 1132.2398572\ttotal: 2m 31s\tremaining: 35.5s\n",
      "810:\tlearn: 1131.7147351\ttotal: 2m 31s\tremaining: 35.3s\n",
      "811:\tlearn: 1131.5146095\ttotal: 2m 31s\tremaining: 35.1s\n",
      "812:\tlearn: 1130.9842502\ttotal: 2m 31s\tremaining: 34.9s\n",
      "813:\tlearn: 1130.6744986\ttotal: 2m 31s\tremaining: 34.7s\n",
      "814:\tlearn: 1130.2666467\ttotal: 2m 32s\tremaining: 34.5s\n",
      "815:\tlearn: 1129.7959022\ttotal: 2m 32s\tremaining: 34.4s\n",
      "816:\tlearn: 1129.5969454\ttotal: 2m 32s\tremaining: 34.2s\n",
      "817:\tlearn: 1129.4268476\ttotal: 2m 32s\tremaining: 34s\n",
      "818:\tlearn: 1129.1899624\ttotal: 2m 32s\tremaining: 33.8s\n",
      "819:\tlearn: 1128.9264898\ttotal: 2m 33s\tremaining: 33.6s\n",
      "820:\tlearn: 1128.7642410\ttotal: 2m 33s\tremaining: 33.4s\n",
      "821:\tlearn: 1128.5107436\ttotal: 2m 33s\tremaining: 33.2s\n",
      "822:\tlearn: 1128.3452328\ttotal: 2m 33s\tremaining: 33s\n",
      "823:\tlearn: 1128.0478529\ttotal: 2m 33s\tremaining: 32.9s\n",
      "824:\tlearn: 1127.8099947\ttotal: 2m 34s\tremaining: 32.7s\n",
      "825:\tlearn: 1127.4994673\ttotal: 2m 34s\tremaining: 32.5s\n",
      "826:\tlearn: 1127.1531791\ttotal: 2m 34s\tremaining: 32.3s\n",
      "827:\tlearn: 1126.9357704\ttotal: 2m 34s\tremaining: 32.1s\n",
      "828:\tlearn: 1126.5383264\ttotal: 2m 34s\tremaining: 31.9s\n",
      "829:\tlearn: 1126.1864275\ttotal: 2m 34s\tremaining: 31.7s\n",
      "830:\tlearn: 1125.9255451\ttotal: 2m 35s\tremaining: 31.6s\n",
      "831:\tlearn: 1125.6029638\ttotal: 2m 35s\tremaining: 31.4s\n",
      "832:\tlearn: 1125.3304619\ttotal: 2m 35s\tremaining: 31.2s\n",
      "833:\tlearn: 1125.1439998\ttotal: 2m 35s\tremaining: 31s\n",
      "834:\tlearn: 1124.7587397\ttotal: 2m 35s\tremaining: 30.8s\n",
      "835:\tlearn: 1124.5390567\ttotal: 2m 36s\tremaining: 30.6s\n",
      "836:\tlearn: 1124.1880682\ttotal: 2m 36s\tremaining: 30.4s\n",
      "837:\tlearn: 1123.7393250\ttotal: 2m 36s\tremaining: 30.3s\n",
      "838:\tlearn: 1123.4556848\ttotal: 2m 36s\tremaining: 30.1s\n",
      "839:\tlearn: 1123.0607882\ttotal: 2m 36s\tremaining: 29.9s\n",
      "840:\tlearn: 1122.8199811\ttotal: 2m 37s\tremaining: 29.7s\n",
      "841:\tlearn: 1122.4913238\ttotal: 2m 37s\tremaining: 29.5s\n",
      "842:\tlearn: 1122.2844743\ttotal: 2m 37s\tremaining: 29.3s\n",
      "843:\tlearn: 1121.9835437\ttotal: 2m 37s\tremaining: 29.1s\n",
      "844:\tlearn: 1121.6430373\ttotal: 2m 37s\tremaining: 29s\n",
      "845:\tlearn: 1121.4522868\ttotal: 2m 38s\tremaining: 28.8s\n",
      "846:\tlearn: 1120.6965236\ttotal: 2m 38s\tremaining: 28.6s\n",
      "847:\tlearn: 1120.3592423\ttotal: 2m 38s\tremaining: 28.4s\n",
      "848:\tlearn: 1120.0324511\ttotal: 2m 38s\tremaining: 28.2s\n",
      "849:\tlearn: 1119.7354314\ttotal: 2m 38s\tremaining: 28s\n",
      "850:\tlearn: 1119.5634384\ttotal: 2m 38s\tremaining: 27.8s\n",
      "851:\tlearn: 1119.2874379\ttotal: 2m 39s\tremaining: 27.6s\n",
      "852:\tlearn: 1119.0533248\ttotal: 2m 39s\tremaining: 27.5s\n",
      "853:\tlearn: 1118.6116378\ttotal: 2m 39s\tremaining: 27.3s\n",
      "854:\tlearn: 1118.1291566\ttotal: 2m 39s\tremaining: 27.1s\n",
      "855:\tlearn: 1117.6786927\ttotal: 2m 39s\tremaining: 26.9s\n",
      "856:\tlearn: 1117.4075593\ttotal: 2m 40s\tremaining: 26.7s\n",
      "857:\tlearn: 1116.6890299\ttotal: 2m 40s\tremaining: 26.5s\n",
      "858:\tlearn: 1116.5473367\ttotal: 2m 40s\tremaining: 26.3s\n",
      "859:\tlearn: 1116.4256187\ttotal: 2m 40s\tremaining: 26.2s\n",
      "860:\tlearn: 1116.1492608\ttotal: 2m 40s\tremaining: 26s\n",
      "861:\tlearn: 1115.8677404\ttotal: 2m 41s\tremaining: 25.8s\n",
      "862:\tlearn: 1115.4629095\ttotal: 2m 41s\tremaining: 25.6s\n",
      "863:\tlearn: 1115.2044953\ttotal: 2m 41s\tremaining: 25.4s\n",
      "864:\tlearn: 1114.8805154\ttotal: 2m 41s\tremaining: 25.2s\n",
      "865:\tlearn: 1114.6635364\ttotal: 2m 41s\tremaining: 25s\n",
      "866:\tlearn: 1114.6048632\ttotal: 2m 42s\tremaining: 24.9s\n",
      "867:\tlearn: 1114.3001074\ttotal: 2m 42s\tremaining: 24.7s\n",
      "868:\tlearn: 1113.8440284\ttotal: 2m 42s\tremaining: 24.5s\n",
      "869:\tlearn: 1113.6554216\ttotal: 2m 42s\tremaining: 24.3s\n",
      "870:\tlearn: 1113.4486774\ttotal: 2m 42s\tremaining: 24.1s\n",
      "871:\tlearn: 1113.2920810\ttotal: 2m 43s\tremaining: 23.9s\n",
      "872:\tlearn: 1113.0398036\ttotal: 2m 43s\tremaining: 23.7s\n",
      "873:\tlearn: 1112.5479611\ttotal: 2m 43s\tremaining: 23.6s\n",
      "874:\tlearn: 1112.3532542\ttotal: 2m 43s\tremaining: 23.4s\n",
      "875:\tlearn: 1111.8616033\ttotal: 2m 43s\tremaining: 23.2s\n",
      "876:\tlearn: 1111.7005978\ttotal: 2m 44s\tremaining: 23s\n",
      "877:\tlearn: 1111.6430152\ttotal: 2m 44s\tremaining: 22.8s\n",
      "878:\tlearn: 1111.3756855\ttotal: 2m 44s\tremaining: 22.6s\n",
      "879:\tlearn: 1111.1004357\ttotal: 2m 44s\tremaining: 22.5s\n",
      "880:\tlearn: 1110.9502486\ttotal: 2m 44s\tremaining: 22.3s\n",
      "881:\tlearn: 1110.7560952\ttotal: 2m 45s\tremaining: 22.1s\n",
      "882:\tlearn: 1110.3762892\ttotal: 2m 45s\tremaining: 21.9s\n",
      "883:\tlearn: 1110.2301887\ttotal: 2m 45s\tremaining: 21.7s\n",
      "884:\tlearn: 1110.0748842\ttotal: 2m 45s\tremaining: 21.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885:\tlearn: 1109.9024556\ttotal: 2m 46s\tremaining: 21.4s\n",
      "886:\tlearn: 1109.6113342\ttotal: 2m 46s\tremaining: 21.2s\n",
      "887:\tlearn: 1109.3089368\ttotal: 2m 46s\tremaining: 21s\n",
      "888:\tlearn: 1108.8401185\ttotal: 2m 46s\tremaining: 20.8s\n",
      "889:\tlearn: 1108.6759082\ttotal: 2m 46s\tremaining: 20.6s\n",
      "890:\tlearn: 1108.5068637\ttotal: 2m 46s\tremaining: 20.4s\n",
      "891:\tlearn: 1108.2891313\ttotal: 2m 47s\tremaining: 20.2s\n",
      "892:\tlearn: 1108.0790432\ttotal: 2m 47s\tremaining: 20.1s\n",
      "893:\tlearn: 1107.7234389\ttotal: 2m 47s\tremaining: 19.9s\n",
      "894:\tlearn: 1107.5746845\ttotal: 2m 47s\tremaining: 19.7s\n",
      "895:\tlearn: 1107.2315113\ttotal: 2m 47s\tremaining: 19.5s\n",
      "896:\tlearn: 1106.8915683\ttotal: 2m 48s\tremaining: 19.3s\n",
      "897:\tlearn: 1106.1613719\ttotal: 2m 48s\tremaining: 19.1s\n",
      "898:\tlearn: 1106.1049655\ttotal: 2m 48s\tremaining: 18.9s\n",
      "899:\tlearn: 1105.7653013\ttotal: 2m 48s\tremaining: 18.7s\n",
      "900:\tlearn: 1105.4565455\ttotal: 2m 48s\tremaining: 18.6s\n",
      "901:\tlearn: 1105.0940541\ttotal: 2m 49s\tremaining: 18.4s\n",
      "902:\tlearn: 1104.9882881\ttotal: 2m 49s\tremaining: 18.2s\n",
      "903:\tlearn: 1104.6549126\ttotal: 2m 49s\tremaining: 18s\n",
      "904:\tlearn: 1104.2938552\ttotal: 2m 49s\tremaining: 17.8s\n",
      "905:\tlearn: 1104.0407085\ttotal: 2m 49s\tremaining: 17.6s\n",
      "906:\tlearn: 1103.8130027\ttotal: 2m 49s\tremaining: 17.4s\n",
      "907:\tlearn: 1103.5480562\ttotal: 2m 50s\tremaining: 17.2s\n",
      "908:\tlearn: 1103.3118839\ttotal: 2m 50s\tremaining: 17.1s\n",
      "909:\tlearn: 1102.9839259\ttotal: 2m 50s\tremaining: 16.9s\n",
      "910:\tlearn: 1102.9218173\ttotal: 2m 50s\tremaining: 16.7s\n",
      "911:\tlearn: 1102.4567436\ttotal: 2m 50s\tremaining: 16.5s\n",
      "912:\tlearn: 1101.9475137\ttotal: 2m 51s\tremaining: 16.3s\n",
      "913:\tlearn: 1101.7532065\ttotal: 2m 51s\tremaining: 16.1s\n",
      "914:\tlearn: 1101.4507947\ttotal: 2m 51s\tremaining: 15.9s\n",
      "915:\tlearn: 1101.0835266\ttotal: 2m 51s\tremaining: 15.7s\n",
      "916:\tlearn: 1100.8476836\ttotal: 2m 51s\tremaining: 15.6s\n",
      "917:\tlearn: 1100.5589436\ttotal: 2m 52s\tremaining: 15.4s\n",
      "918:\tlearn: 1100.0156486\ttotal: 2m 52s\tremaining: 15.2s\n",
      "919:\tlearn: 1099.6326665\ttotal: 2m 52s\tremaining: 15s\n",
      "920:\tlearn: 1099.3098639\ttotal: 2m 52s\tremaining: 14.8s\n",
      "921:\tlearn: 1098.9200513\ttotal: 2m 52s\tremaining: 14.6s\n",
      "922:\tlearn: 1098.7330557\ttotal: 2m 53s\tremaining: 14.4s\n",
      "923:\tlearn: 1098.4714244\ttotal: 2m 53s\tremaining: 14.3s\n",
      "924:\tlearn: 1098.2891245\ttotal: 2m 53s\tremaining: 14.1s\n",
      "925:\tlearn: 1098.0999229\ttotal: 2m 53s\tremaining: 13.9s\n",
      "926:\tlearn: 1097.7742711\ttotal: 2m 53s\tremaining: 13.7s\n",
      "927:\tlearn: 1097.4946753\ttotal: 2m 54s\tremaining: 13.5s\n",
      "928:\tlearn: 1097.1778347\ttotal: 2m 54s\tremaining: 13.3s\n",
      "929:\tlearn: 1096.8595960\ttotal: 2m 54s\tremaining: 13.1s\n",
      "930:\tlearn: 1096.6020256\ttotal: 2m 54s\tremaining: 12.9s\n",
      "931:\tlearn: 1096.3559384\ttotal: 2m 54s\tremaining: 12.8s\n",
      "932:\tlearn: 1096.0320012\ttotal: 2m 55s\tremaining: 12.6s\n",
      "933:\tlearn: 1095.8646953\ttotal: 2m 55s\tremaining: 12.4s\n",
      "934:\tlearn: 1095.7132738\ttotal: 2m 55s\tremaining: 12.2s\n",
      "935:\tlearn: 1095.6324545\ttotal: 2m 55s\tremaining: 12s\n",
      "936:\tlearn: 1095.3752396\ttotal: 2m 55s\tremaining: 11.8s\n",
      "937:\tlearn: 1095.2015062\ttotal: 2m 56s\tremaining: 11.6s\n",
      "938:\tlearn: 1094.8014143\ttotal: 2m 56s\tremaining: 11.4s\n",
      "939:\tlearn: 1094.6150569\ttotal: 2m 56s\tremaining: 11.3s\n",
      "940:\tlearn: 1094.3804855\ttotal: 2m 56s\tremaining: 11.1s\n",
      "941:\tlearn: 1094.1886746\ttotal: 2m 56s\tremaining: 10.9s\n",
      "942:\tlearn: 1093.9326020\ttotal: 2m 57s\tremaining: 10.7s\n",
      "943:\tlearn: 1093.5431762\ttotal: 2m 57s\tremaining: 10.5s\n",
      "944:\tlearn: 1093.2471503\ttotal: 2m 57s\tremaining: 10.3s\n",
      "945:\tlearn: 1093.0253784\ttotal: 2m 57s\tremaining: 10.1s\n",
      "946:\tlearn: 1092.7394402\ttotal: 2m 57s\tremaining: 9.95s\n",
      "947:\tlearn: 1092.3529103\ttotal: 2m 58s\tremaining: 9.76s\n",
      "948:\tlearn: 1092.0795885\ttotal: 2m 58s\tremaining: 9.58s\n",
      "949:\tlearn: 1091.8269856\ttotal: 2m 58s\tremaining: 9.39s\n",
      "950:\tlearn: 1091.4669707\ttotal: 2m 58s\tremaining: 9.21s\n",
      "951:\tlearn: 1091.1826483\ttotal: 2m 58s\tremaining: 9.02s\n",
      "952:\tlearn: 1091.0397018\ttotal: 2m 59s\tremaining: 8.83s\n",
      "953:\tlearn: 1090.7173133\ttotal: 2m 59s\tremaining: 8.64s\n",
      "954:\tlearn: 1090.6507524\ttotal: 2m 59s\tremaining: 8.46s\n",
      "955:\tlearn: 1090.5183291\ttotal: 2m 59s\tremaining: 8.27s\n",
      "956:\tlearn: 1090.3168572\ttotal: 2m 59s\tremaining: 8.08s\n",
      "957:\tlearn: 1090.1988605\ttotal: 3m\tremaining: 7.9s\n",
      "958:\tlearn: 1090.0785875\ttotal: 3m\tremaining: 7.71s\n",
      "959:\tlearn: 1089.6675440\ttotal: 3m\tremaining: 7.52s\n",
      "960:\tlearn: 1089.2998589\ttotal: 3m\tremaining: 7.33s\n",
      "961:\tlearn: 1088.9646804\ttotal: 3m\tremaining: 7.15s\n",
      "962:\tlearn: 1088.7270843\ttotal: 3m 1s\tremaining: 6.96s\n",
      "963:\tlearn: 1088.4579958\ttotal: 3m 1s\tremaining: 6.77s\n",
      "964:\tlearn: 1088.1607650\ttotal: 3m 1s\tremaining: 6.58s\n",
      "965:\tlearn: 1088.0704327\ttotal: 3m 1s\tremaining: 6.39s\n",
      "966:\tlearn: 1087.7747782\ttotal: 3m 1s\tremaining: 6.21s\n",
      "967:\tlearn: 1087.4169832\ttotal: 3m 2s\tremaining: 6.02s\n",
      "968:\tlearn: 1087.1002697\ttotal: 3m 2s\tremaining: 5.83s\n",
      "969:\tlearn: 1086.7911408\ttotal: 3m 2s\tremaining: 5.64s\n",
      "970:\tlearn: 1086.5667405\ttotal: 3m 2s\tremaining: 5.46s\n",
      "971:\tlearn: 1086.3535402\ttotal: 3m 2s\tremaining: 5.27s\n",
      "972:\tlearn: 1086.1333192\ttotal: 3m 3s\tremaining: 5.08s\n",
      "973:\tlearn: 1085.9869933\ttotal: 3m 3s\tremaining: 4.89s\n",
      "974:\tlearn: 1085.7137004\ttotal: 3m 3s\tremaining: 4.71s\n",
      "975:\tlearn: 1085.5010934\ttotal: 3m 3s\tremaining: 4.52s\n",
      "976:\tlearn: 1085.2878844\ttotal: 3m 3s\tremaining: 4.33s\n",
      "977:\tlearn: 1085.0742420\ttotal: 3m 4s\tremaining: 4.14s\n",
      "978:\tlearn: 1084.9530510\ttotal: 3m 4s\tremaining: 3.95s\n",
      "979:\tlearn: 1084.6033646\ttotal: 3m 4s\tremaining: 3.77s\n",
      "980:\tlearn: 1084.4225302\ttotal: 3m 4s\tremaining: 3.58s\n",
      "981:\tlearn: 1084.1164274\ttotal: 3m 4s\tremaining: 3.39s\n",
      "982:\tlearn: 1083.7182194\ttotal: 3m 5s\tremaining: 3.2s\n",
      "983:\tlearn: 1083.4962153\ttotal: 3m 5s\tremaining: 3.01s\n",
      "984:\tlearn: 1083.4344032\ttotal: 3m 5s\tremaining: 2.82s\n",
      "985:\tlearn: 1083.0699821\ttotal: 3m 5s\tremaining: 2.64s\n",
      "986:\tlearn: 1082.8716690\ttotal: 3m 5s\tremaining: 2.45s\n",
      "987:\tlearn: 1082.4491543\ttotal: 3m 6s\tremaining: 2.26s\n",
      "988:\tlearn: 1082.1234116\ttotal: 3m 6s\tremaining: 2.07s\n",
      "989:\tlearn: 1081.9099026\ttotal: 3m 6s\tremaining: 1.88s\n",
      "990:\tlearn: 1081.6673057\ttotal: 3m 6s\tremaining: 1.7s\n",
      "991:\tlearn: 1081.4462548\ttotal: 3m 6s\tremaining: 1.51s\n",
      "992:\tlearn: 1081.1573739\ttotal: 3m 7s\tremaining: 1.32s\n",
      "993:\tlearn: 1080.9186400\ttotal: 3m 7s\tremaining: 1.13s\n",
      "994:\tlearn: 1080.7397586\ttotal: 3m 7s\tremaining: 942ms\n",
      "995:\tlearn: 1080.5383995\ttotal: 3m 7s\tremaining: 753ms\n",
      "996:\tlearn: 1080.4570601\ttotal: 3m 7s\tremaining: 565ms\n",
      "997:\tlearn: 1080.0637060\ttotal: 3m 7s\tremaining: 377ms\n",
      "998:\tlearn: 1079.8713052\ttotal: 3m 8s\tremaining: 188ms\n",
      "999:\tlearn: 1079.5787640\ttotal: 3m 8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat = CatBoostRegressor(max_depth=10)\n",
    "cat = cat.fit(x_train,y_train)\n",
    "y_pred = cat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "palestinian-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_train: 0.9162233014964292\n",
      "Roc_test: 0.8688858951757088\n"
     ]
    }
   ],
   "source": [
    "print(\"Roc_train:\",metrics.roc_auc_score(y_train, cat.predict(x_train)))\n",
    "print(\"Roc_test:\",metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "breathing-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_train: 0.9118860961282291\n",
      "F1_test: 0.8633693196083354\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_train:\",metrics.f1_score(y_train, cat.predict(x_train)))\n",
    "print(\"F1_test:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cultural-sweden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini_train: 0.8324466029928583\n",
      "Gini_test: 0.7377717903514176\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini_train:\",2*metrics.roc_auc_score(y_train, cat.predict(x_train))-1)\n",
    "print(\"Gini_test:\",2*metrics.roc_auc_score(y_test, y_pred)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "leading-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 0.9170327825032042\n",
      "Accuracy_test: 0.8694546617623541\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.accuracy_score(y_train, cat.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "chinese-stationery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 1079.5787639438906\n",
      "Accuracy_test: 1040.7437145157078\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_squared_error(y_train, cat.predict(x_train), squared = False))\n",
    "print(\"Accuracy_test:\",metrics.mean_squared_error(y_test, y_pred, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "further-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 644.7470752167267\n",
      "Accuracy_test: 750.1282509515946\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_absolute_error(y_train, cat.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "chicken-desperate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Дата</th>\n",
       "      <th>ДатаДоставки</th>\n",
       "      <th>НомерЗаказаНаСайте</th>\n",
       "      <th>НовыйСтатус</th>\n",
       "      <th>СуммаЗаказаНаСайте</th>\n",
       "      <th>СуммаДокумента</th>\n",
       "      <th>МетодДоставки</th>\n",
       "      <th>ФормаОплаты</th>\n",
       "      <th>Регион</th>\n",
       "      <th>Группа2</th>\n",
       "      <th>...</th>\n",
       "      <th>ДатаЗаказаНаСайте</th>\n",
       "      <th>Телефон_new</th>\n",
       "      <th>ЭлектроннаяПочта_new</th>\n",
       "      <th>Клиент</th>\n",
       "      <th>ID_SKU</th>\n",
       "      <th>ГородМагазина</th>\n",
       "      <th>МагазинЗаказа</th>\n",
       "      <th>Доставка</th>\n",
       "      <th>Id</th>\n",
       "      <th>МаржаПолная</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>06.07.2017 0:00</td>\n",
       "      <td>5031788_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1 634</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТЕКСТИЛЬ, ТРИКОТАЖ</td>\n",
       "      <td>...</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>116117_tu17@mail.ru</td>\n",
       "      <td>Татьяна</td>\n",
       "      <td>IDL00051334048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>26.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>06.07.2017 0:00</td>\n",
       "      <td>5031788_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1 634</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТЕКСТИЛЬ, ТРИКОТАЖ</td>\n",
       "      <td>...</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>116117_tu17@mail.ru</td>\n",
       "      <td>Татьяна</td>\n",
       "      <td>IDL00051367351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>26.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>06.07.2017 0:00</td>\n",
       "      <td>5031788_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1 634</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТЕКСТИЛЬ, ТРИКОТАЖ</td>\n",
       "      <td>...</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>116117_tu17@mail.ru</td>\n",
       "      <td>Татьяна</td>\n",
       "      <td>IDL00007611755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>8.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>06.07.2017 0:00</td>\n",
       "      <td>5031788_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1 634</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТЕКСТИЛЬ, ТРИКОТАЖ</td>\n",
       "      <td>...</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>116117_tu17@mail.ru</td>\n",
       "      <td>Татьяна</td>\n",
       "      <td>IDL00014478250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-07</td>\n",
       "      <td>06.07.2017 0:00</td>\n",
       "      <td>5031788_TR</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1 634</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТЕКСТИЛЬ, ТРИКОТАЖ</td>\n",
       "      <td>...</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>116117_tu17@mail.ru</td>\n",
       "      <td>Татьяна</td>\n",
       "      <td>IDL00001209351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>63.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776244</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>16.10.2017 0:00</td>\n",
       "      <td>5775649_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>1 924</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ДЕТСКОЕ ПИТАНИЕ</td>\n",
       "      <td>...</td>\n",
       "      <td>12.10.2017 0:00</td>\n",
       "      <td>55575054-56515654485370</td>\n",
       "      <td>116117_tu20@yandex.ru</td>\n",
       "      <td>Наталия</td>\n",
       "      <td>ID000sm-0611250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55575054-56515654485370</td>\n",
       "      <td>27.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776245</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>16.10.2017 0:00</td>\n",
       "      <td>5775649_ES</td>\n",
       "      <td>К отгрузке</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>1 924</td>\n",
       "      <td>Курьерская</td>\n",
       "      <td>Наличная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ТОВАРЫ ДЛЯ КОРМЛЕНИЯ</td>\n",
       "      <td>...</td>\n",
       "      <td>12.10.2017 0:00</td>\n",
       "      <td>55575054-56515654485370</td>\n",
       "      <td>116117_tu20@yandex.ru</td>\n",
       "      <td>Наталия</td>\n",
       "      <td>IDL00018658654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55575054-56515654485370</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776246</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>15.10.2017 0:00</td>\n",
       "      <td>5775667_ES</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1 232</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ДЕТСКОЕ ПИТАНИЕ</td>\n",
       "      <td>...</td>\n",
       "      <td>12.10.2017 0:00</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>115117_su16@mail.ru</td>\n",
       "      <td>Надия</td>\n",
       "      <td>ID10009087553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776247</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>15.10.2017 0:00</td>\n",
       "      <td>5775667_ES</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1 232</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ДЕТСКОЕ ПИТАНИЕ</td>\n",
       "      <td>...</td>\n",
       "      <td>12.10.2017 0:00</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>115117_su16@mail.ru</td>\n",
       "      <td>Надия</td>\n",
       "      <td>ID000sm-0705856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776248</th>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>15.10.2017 0:00</td>\n",
       "      <td>5775667_ES</td>\n",
       "      <td>Доставлен</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1 232</td>\n",
       "      <td>Магазины</td>\n",
       "      <td>Безналичная</td>\n",
       "      <td>Москва</td>\n",
       "      <td>ПОДГУЗНИКИ</td>\n",
       "      <td>...</td>\n",
       "      <td>12.10.2017 0:00</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>115117_su16@mail.ru</td>\n",
       "      <td>Надия</td>\n",
       "      <td>IDL00011352755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>-321.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748774 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Дата     ДатаДоставки НомерЗаказаНаСайте НовыйСтатус  \\\n",
       "0      2017-01-07  06.07.2017 0:00         5031788_TR   Доставлен   \n",
       "1      2017-01-07  06.07.2017 0:00         5031788_TR   Доставлен   \n",
       "2      2017-01-07  06.07.2017 0:00         5031788_TR   Доставлен   \n",
       "3      2017-01-07  06.07.2017 0:00         5031788_TR   Доставлен   \n",
       "4      2017-01-07  06.07.2017 0:00         5031788_TR   Доставлен   \n",
       "...           ...              ...                ...         ...   \n",
       "776244 2017-12-10  16.10.2017 0:00         5775649_ES  К отгрузке   \n",
       "776245 2017-12-10  16.10.2017 0:00         5775649_ES  К отгрузке   \n",
       "776246 2017-12-10  15.10.2017 0:00         5775667_ES   Доставлен   \n",
       "776247 2017-12-10  15.10.2017 0:00         5775667_ES   Доставлен   \n",
       "776248 2017-12-10  15.10.2017 0:00         5775667_ES   Доставлен   \n",
       "\n",
       "        СуммаЗаказаНаСайте СуммаДокумента МетодДоставки  ФормаОплаты  Регион  \\\n",
       "0                   1634.0          1 634      Магазины  Безналичная  Москва   \n",
       "1                   1634.0          1 634      Магазины  Безналичная  Москва   \n",
       "2                   1634.0          1 634      Магазины  Безналичная  Москва   \n",
       "3                   1634.0          1 634      Магазины  Безналичная  Москва   \n",
       "4                   1634.0          1 634      Магазины  Безналичная  Москва   \n",
       "...                    ...            ...           ...          ...     ...   \n",
       "776244              1924.0          1 924    Курьерская     Наличная  Москва   \n",
       "776245              1924.0          1 924    Курьерская     Наличная  Москва   \n",
       "776246              1232.0          1 232      Магазины  Безналичная  Москва   \n",
       "776247              1232.0          1 232      Магазины  Безналичная  Москва   \n",
       "776248              1232.0          1 232      Магазины  Безналичная  Москва   \n",
       "\n",
       "                     Группа2  ... ДатаЗаказаНаСайте              Телефон_new  \\\n",
       "0         ТЕКСТИЛЬ, ТРИКОТАЖ  ...   30.06.2017 0:00  55574948-52495050484877   \n",
       "1         ТЕКСТИЛЬ, ТРИКОТАЖ  ...   30.06.2017 0:00  55574948-52495050484877   \n",
       "2         ТЕКСТИЛЬ, ТРИКОТАЖ  ...   30.06.2017 0:00  55574948-52495050484877   \n",
       "3         ТЕКСТИЛЬ, ТРИКОТАЖ  ...   30.06.2017 0:00  55574948-52495050484877   \n",
       "4         ТЕКСТИЛЬ, ТРИКОТАЖ  ...   30.06.2017 0:00  55574948-52495050484877   \n",
       "...                      ...  ...               ...                      ...   \n",
       "776244       ДЕТСКОЕ ПИТАНИЕ  ...   12.10.2017 0:00  55575054-56515654485370   \n",
       "776245  ТОВАРЫ ДЛЯ КОРМЛЕНИЯ  ...   12.10.2017 0:00  55575054-56515654485370   \n",
       "776246       ДЕТСКОЕ ПИТАНИЕ  ...   12.10.2017 0:00  55574851-50565452485270   \n",
       "776247       ДЕТСКОЕ ПИТАНИЕ  ...   12.10.2017 0:00  55574851-50565452485270   \n",
       "776248            ПОДГУЗНИКИ  ...   12.10.2017 0:00  55574851-50565452485270   \n",
       "\n",
       "         ЭлектроннаяПочта_new   Клиент           ID_SKU ГородМагазина  \\\n",
       "0         116117_tu17@mail.ru  Татьяна   IDL00051334048             0   \n",
       "1         116117_tu17@mail.ru  Татьяна   IDL00051367351             0   \n",
       "2         116117_tu17@mail.ru  Татьяна   IDL00007611755             0   \n",
       "3         116117_tu17@mail.ru  Татьяна   IDL00014478250             0   \n",
       "4         116117_tu17@mail.ru  Татьяна   IDL00001209351             0   \n",
       "...                       ...      ...              ...           ...   \n",
       "776244  116117_tu20@yandex.ru  Наталия  ID000sm-0611250             0   \n",
       "776245  116117_tu20@yandex.ru  Наталия   IDL00018658654             0   \n",
       "776246    115117_su16@mail.ru    Надия    ID10009087553             0   \n",
       "776247    115117_su16@mail.ru    Надия  ID000sm-0705856             0   \n",
       "776248    115117_su16@mail.ru    Надия   IDL00011352755             0   \n",
       "\n",
       "       МагазинЗаказа  Доставка                       Id  МаржаПолная  \n",
       "0                  0       1.0  55574948-52495050484877        26.90  \n",
       "1                  0       1.0  55574948-52495050484877        26.90  \n",
       "2                  0       1.0  55574948-52495050484877         8.04  \n",
       "3                  0       1.0  55574948-52495050484877         5.79  \n",
       "4                  0       1.0  55574948-52495050484877        63.79  \n",
       "...              ...       ...                      ...          ...  \n",
       "776244             0       0.0  55575054-56515654485370        27.83  \n",
       "776245             0       0.0  55575054-56515654485370       122.00  \n",
       "776246             0       0.0  55574851-50565452485270         1.11  \n",
       "776247             0       0.0  55574851-50565452485270         1.11  \n",
       "776248             0       0.0  55574851-50565452485270      -321.08  \n",
       "\n",
       "[748774 rows x 41 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "binary-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = df_last.merge(mean_non_dupe_bought, left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "df_last = df_last.rename(columns={'Итог':'СреднийЧекВыкупленные'})\n",
    "df_last = df_last.fillna(0)\n",
    "df_last['Цель'] = df_last['СреднийЧекВыкупленные']\n",
    "#display = display.drop(columns = ['Цель'])\n",
    "display = display.merge(df_last[['Телефон_new', 'Цель']], left_on='Id', right_on='Телефон_new', how = 'left')\n",
    "display = display.drop(columns=['Телефон_new'])\n",
    "display = display.fillna(0)\n",
    "x = display.drop(columns = ['Id', 'Гео', 'Цель']).values\n",
    "y = display.Цель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "oriented-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.to_csv('display_reg.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "flush-pattern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55574954-57485351535070    198\n",
       "55574954-50565449575671    121\n",
       "55574951-54554848555476    115\n",
       "55574952-53485057564972    113\n",
       "55574954-50494954545575    109\n",
       "                          ... \n",
       "55574954-53555656505278      1\n",
       "55575049-54515755555570      1\n",
       "55574856-50545551505272      1\n",
       "55574851-48575651525077      1\n",
       "55575454-49525248554870      1\n",
       "Name: Id, Length: 123877, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model['Id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "directed-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>КоличествоЧеков</th>\n",
       "      <th>СреднийЧек</th>\n",
       "      <th>СреднееЧислоТоваровЧека</th>\n",
       "      <th>Выручка</th>\n",
       "      <th>КоличествоТоваров</th>\n",
       "      <th>СредняяМаржа</th>\n",
       "      <th>КоличествоЧековВыкупленные</th>\n",
       "      <th>СреднийЧекВыкупленные</th>\n",
       "      <th>СреднееЧислоТоваровЧекаВыкупленные</th>\n",
       "      <th>...</th>\n",
       "      <th>СВЕТООТРАЖАЮЩИЕ ЭЛЕМЕНТЫ</th>\n",
       "      <th>ВЕТАПТЕКА</th>\n",
       "      <th>ВИТАМИНЫ/БАДЫ</th>\n",
       "      <th>ТОВАРЫ ДЛЯ ЧЕРЕПАХ И РЕПТИЛИЙ</th>\n",
       "      <th>ТОВАРЫ ДЛЯ ХОРЬКОВ</th>\n",
       "      <th>ЗЕРКАЛА</th>\n",
       "      <th>ГЛАДИЛЬНЫЕ ДОСКИ,СУШИЛКИ</th>\n",
       "      <th>ТЕХНИКА ДЛЯ ДОМА</th>\n",
       "      <th>Гео</th>\n",
       "      <th>Цель</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55574948-52495050484877</td>\n",
       "      <td>1</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>13</td>\n",
       "      <td>38.249231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55575656-49565651494970</td>\n",
       "      <td>1</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.941818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55575155-54535648525672</td>\n",
       "      <td>4</td>\n",
       "      <td>15147.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>85842.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2365.939091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17498.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55575456-55545450525776</td>\n",
       "      <td>2</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>5264.0</td>\n",
       "      <td>9</td>\n",
       "      <td>192.295000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55575054-54575350505479</td>\n",
       "      <td>3</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>5</td>\n",
       "      <td>76.240000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208426</th>\n",
       "      <td>55574954-52495355555471</td>\n",
       "      <td>1</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6453.0</td>\n",
       "      <td>7</td>\n",
       "      <td>222.321429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208427</th>\n",
       "      <td>55575649-57495654575771</td>\n",
       "      <td>1</td>\n",
       "      <td>578.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>479.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208428</th>\n",
       "      <td>55575048-54515157545679</td>\n",
       "      <td>1</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1</td>\n",
       "      <td>435.070000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Регионы</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208429</th>\n",
       "      <td>55575054-56575557485677</td>\n",
       "      <td>1</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.480000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>1059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208430</th>\n",
       "      <td>55574851-50565452485270</td>\n",
       "      <td>1</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-106.286667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Москва</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208431 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Id  КоличествоЧеков  СреднийЧек  \\\n",
       "0       55574948-52495050484877                1      1634.0   \n",
       "1       55575656-49565651494970                1      1915.0   \n",
       "2       55575155-54535648525672                4     15147.0   \n",
       "3       55575456-55545450525776                2      2782.0   \n",
       "4       55575054-54575350505479                3       599.0   \n",
       "...                         ...              ...         ...   \n",
       "208426  55574954-52495355555471                1      6453.0   \n",
       "208427  55575649-57495654575771                1       578.0   \n",
       "208428  55575048-54515157545679                1      1058.0   \n",
       "208429  55575054-56575557485677                1      1059.0   \n",
       "208430  55574851-50565452485270                1      1232.0   \n",
       "\n",
       "        СреднееЧислоТоваровЧека  Выручка  КоличествоТоваров  СредняяМаржа  \\\n",
       "0                         1.000   1585.0                 13     38.249231   \n",
       "1                         1.000   1816.0                 11     -0.941818   \n",
       "2                         1.000  85842.0                 11   2365.939091   \n",
       "3                         1.125   5264.0                  9    192.295000   \n",
       "4                         1.000   1650.0                  5     76.240000   \n",
       "...                         ...      ...                ...           ...   \n",
       "208426                    1.000   6453.0                  7    222.321429   \n",
       "208427                    1.000    479.0                  2     19.640000   \n",
       "208428                    1.000    909.0                  1    435.070000   \n",
       "208429                    1.000   1059.0                  1     41.480000   \n",
       "208430                    1.000   1232.0                  3   -106.286667   \n",
       "\n",
       "        КоличествоЧековВыкупленные  СреднийЧекВыкупленные  \\\n",
       "0                              1.0                 1585.0   \n",
       "1                              1.0                 1816.0   \n",
       "2                              3.0                17498.0   \n",
       "3                              2.0                 2632.0   \n",
       "4                              1.0                  310.0   \n",
       "...                            ...                    ...   \n",
       "208426                         1.0                 1018.0   \n",
       "208427                         1.0                  479.0   \n",
       "208428                         1.0                  909.0   \n",
       "208429                         1.0                 1059.0   \n",
       "208430                         1.0                 1232.0   \n",
       "\n",
       "        СреднееЧислоТоваровЧекаВыкупленные  ...  СВЕТООТРАЖАЮЩИЕ ЭЛЕМЕНТЫ  \\\n",
       "0                                 1.000000  ...                       0.0   \n",
       "1                                 1.000000  ...                       0.0   \n",
       "2                                 0.545455  ...                       0.0   \n",
       "3                                 1.125000  ...                       0.0   \n",
       "4                                 0.200000  ...                       0.0   \n",
       "...                                    ...  ...                       ...   \n",
       "208426                            0.285714  ...                       0.0   \n",
       "208427                            1.000000  ...                       0.0   \n",
       "208428                            1.000000  ...                       0.0   \n",
       "208429                            1.000000  ...                       0.0   \n",
       "208430                            1.000000  ...                       0.0   \n",
       "\n",
       "        ВЕТАПТЕКА  ВИТАМИНЫ/БАДЫ  ТОВАРЫ ДЛЯ ЧЕРЕПАХ И РЕПТИЛИЙ  \\\n",
       "0             0.0            0.0                            0.0   \n",
       "1             0.0            0.0                            0.0   \n",
       "2             0.0            0.0                            0.0   \n",
       "3             0.0            0.0                            0.0   \n",
       "4             0.0            0.0                            0.0   \n",
       "...           ...            ...                            ...   \n",
       "208426        0.0            0.0                            0.0   \n",
       "208427        0.0            0.0                            0.0   \n",
       "208428        0.0            0.0                            0.0   \n",
       "208429        0.0            0.0                            0.0   \n",
       "208430        0.0            0.0                            0.0   \n",
       "\n",
       "        ТОВАРЫ ДЛЯ ХОРЬКОВ  ЗЕРКАЛА  ГЛАДИЛЬНЫЕ ДОСКИ,СУШИЛКИ  \\\n",
       "0                      0.0      0.0                       0.0   \n",
       "1                      0.0      0.0                       0.0   \n",
       "2                      0.0      0.0                       0.0   \n",
       "3                      0.0      0.0                       0.0   \n",
       "4                      0.0      0.0                       0.0   \n",
       "...                    ...      ...                       ...   \n",
       "208426                 0.0      0.0                       0.0   \n",
       "208427                 0.0      0.0                       0.0   \n",
       "208428                 0.0      0.0                       0.0   \n",
       "208429                 0.0      0.0                       0.0   \n",
       "208430                 0.0      0.0                       0.0   \n",
       "\n",
       "        ТЕХНИКА ДЛЯ ДОМА      Гео    Цель  \n",
       "0                    0.0   Москва     0.0  \n",
       "1                    0.0  Регионы     0.0  \n",
       "2                    0.0  Регионы     0.0  \n",
       "3                    0.0   Москва     0.0  \n",
       "4                    0.0   Москва     0.0  \n",
       "...                  ...      ...     ...  \n",
       "208426               0.0   Москва     0.0  \n",
       "208427               0.0  Регионы     0.0  \n",
       "208428               0.0  Регионы     0.0  \n",
       "208429               0.0   Москва  1059.0  \n",
       "208430               0.0   Москва     0.0  \n",
       "\n",
       "[208431 rows x 130 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "industrial-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = preprocessing.StandardScaler().fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-bearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "arabic-ballet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "intelligent-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValMean:                                                                                                          \n",
      "0.6625582307251258                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7540986063288968                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7181952112416576                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7977093440931213                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7530967374563614                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7828233784925068                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7726676118471095                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7460157519456093                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7669705042700891                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6921762569926352                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8107404385979365                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6955728272549712                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7881261907246758                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.5404561058588203                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7638623000258815                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7522039126961332                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6830587936440996                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7578648248739905                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7945290426986321                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7503327913756802                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.614359520610006                                                                                                      \n",
      "CrossValMean:                                                                                                          \n",
      "0.8382431468729319                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7730227897397365                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8408726931771843                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8438992421209899                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.535706265133561                                                                                                      \n",
      "CrossValMean:                                                                                                          \n",
      "0.8438646520903111                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8339004474254791                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.82957109854263                                                                                                       \n",
      "CrossValMean:                                                                                                          \n",
      "0.8092572758004118                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7666074288164723                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6460185130126018                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7745866617295215                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.725073153632804                                                                                                      \n",
      "CrossValMean:                                                                                                          \n",
      "0.820754650591513                                                                                                      \n",
      "CrossValMean:                                                                                                          \n",
      "0.8107482031491223                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8295928716196671                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8385090284013993                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8218772719545435                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6535620996753662                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7765152714076812                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6684101439807856                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8103741446912428                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.6688500540567187                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.668023088922594                                                                                                      \n",
      "CrossValMean:                                                                                                          \n",
      "0.7149384507616574                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.7248231301992117                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8022386872579162                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8194917260086773                                                                                                     \n",
      "CrossValMean:                                                                                                          \n",
      "0.8091317050558059                                                                                                     \n",
      "100%|███████████████████████████████████████████████| 50/50 [51:32<00:00, 61.84s/trial, best loss: 0.15610075787901012]\n",
      "Best:  {'colsample_bytree': 0.12, 'gamma': 0.01, 'learning_rate': 0.09, 'max_depth': 23, 'min_child_weight': 2.0, 'subsample': 0.98}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    classifier = XGBRegressor(max_depth = int(space['max_depth']),\n",
    "                            learning_rate = space['learning_rate'],\n",
    "                            gamma = space['gamma'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                            colsample_bytree = space['colsample_bytree']\n",
    "                            )\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 3)\n",
    "    CrossValMean = accuracies.mean()\n",
    "\n",
    "    print(\"CrossValMean:\", CrossValMean)\n",
    "\n",
    "    return{'loss':1-CrossValMean, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fuzzy-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.07616444e-01, -4.89377938e-01, -1.91219916e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04],\n",
       "       [-6.07616444e-01,  3.70442106e-01, -5.65553734e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04],\n",
       "       [ 7.62372973e-02, -5.77834405e-01, -3.81670455e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04],\n",
       "       ...,\n",
       "       [ 7.60091038e-01, -8.62281195e-01, -5.65553734e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04],\n",
       "       [ 1.10201791e+00, -5.00544432e-01,  7.37390643e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04],\n",
       "       [-2.65689573e-01, -6.00914528e-01, -5.65553734e-01, ...,\n",
       "         0.00000000e+00, -7.42035802e-04, -7.42035802e-04]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "alpine-connection",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-0af9979ed4f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'colsample_bytree'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.09\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_child_weight'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subsample'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.98\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mxgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mxgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         train_dmatrix, evals = self._wrap_evaluation_matrices(\n\u001b[0m\u001b[0;32m    579\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[0mfeature_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(self, X, y, group, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, eval_group, label_transform)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         train_dmatrix = DMatrix(data=X, label=y, weight=sample_weight,\n\u001b[0m\u001b[0;32m    266\u001b[0m                                 \u001b[0mbase_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                                 missing=self.missing, nthread=self.n_jobs)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdispatch_data_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_from_scipy_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         return _from_numpy_array(data, missing, threads, feature_names,\n\u001b[0m\u001b[0;32m    531\u001b[0m                                  feature_types)\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[1;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_transform_np_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     _check_call(_LIB.XGDMatrixCreateFromMat_omp(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mflatten\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "best = {'colsample_bytree': 0.12, 'gamma': 0.01, 'learning_rate': 0.09, 'max_depth': 23, 'min_child_weight': 2.0, 'subsample': 0.98}\n",
    "xgb = xgboost.XGBRegressor(**best)\n",
    "xgb = xgb.fit(x_train,y_train)\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "egyptian-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_train: 0.997502720305105\n",
      "Roc_test: 0.9661699966379124\n"
     ]
    }
   ],
   "source": [
    "print(\"Roc_train:\",metrics.roc_auc_score(y_train, xgb.predict(x_train)))\n",
    "print(\"Roc_test:\",metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tracked-reality",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-8377f4332561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1_train:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1_test:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1272\u001b[0m                          str(average_options))\n\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "print(\"F1_train:\",metrics.f1_score(y_train, xgb.predict(x_train)))\n",
    "print(\"F1_test:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gini_train:\",2*metrics.roc_auc_score(y_train, xgb.predict(x_train))-1)\n",
    "print(\"Gini_test:\",2*metrics.roc_auc_score(y_test, y_pred)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "amazing-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 227797.29215518502\n",
      "Accuracy_test: 1083147.479303953\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_squared_error(y_train, xgb.predict(x_train), squared = True))\n",
    "print(\"Accuracy_test:\",metrics.mean_squared_error(y_test, y_pred, squared = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dominant-inflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_train: 219.9167017890073\n",
      "Accuracy_test: 447.5049725533524\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_train:\",metrics.mean_absolute_error(y_train, xgb.predict(x_train)))\n",
    "print(\"Accuracy_test:\",metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "theoretical-ebony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145901, 127)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-diana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
